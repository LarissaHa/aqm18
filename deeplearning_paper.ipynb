{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: bitops\n",
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.4.4\"Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.4.4\"Warning message:\n",
      "\"package 'e1071' was built under R version 3.4.3\"Warning message:\n",
      "\"package 'h2o' was built under R version 3.4.4\"\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Your next step is to start H2O:\n",
      "    > h2o.init()\n",
      "\n",
      "For H2O package documentation, ask for help:\n",
      "    > ??h2o\n",
      "\n",
      "After starting H2O, you can use the Web UI at http://localhost:54321\n",
      "For more information visit http://docs.h2o.ai\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Attaching package: 'h2o'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cor, sd, var\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n",
      "    colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n",
      "    log10, log1p, log2, round, signif, trunc\n",
      "\n",
      "Warning message:\n",
      "\"package 'statmod' was built under R version 3.4.4\"Warning message:\n",
      "\"package 'corrplot' was built under R version 3.4.4\"corrplot 0.84 loaded\n",
      "\n",
      "Attaching package: 'data.table'\n",
      "\n",
      "The following objects are masked from 'package:h2o':\n",
      "\n",
      "    hour, month, week, year\n",
      "\n",
      "Warning message:\n",
      "\"package 'reshape2' was built under R version 3.4.4\"\n",
      "Attaching package: 'reshape2'\n",
      "\n",
      "The following objects are masked from 'package:data.table':\n",
      "\n",
      "    dcast, melt\n",
      "\n",
      "Warning message:\n",
      "\"package 'ROSE' was built under R version 3.4.4\"Loaded ROSE 0.0-3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(RCurl)\n",
    "library(jsonlite)\n",
    "library(caret)\n",
    "library(ggplot2)\n",
    "library(e1071)\n",
    "library(h2o)\n",
    "library(statmod)\n",
    "library(MASS)\n",
    "library(corrplot)\n",
    "library(data.table)\n",
    "library(reshape2)\n",
    "library(ROSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.scaled <- read.table(\"ess-scaled.csv\", header=TRUE, sep=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.scaled <- data.scaled[,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_size <- floor(0.9 * nrow(data.scaled))\n",
    "set.seed(1234)\n",
    "train_ind <- sample(seq_len(nrow(data.scaled)), size = smp_size)\n",
    "train <- data.scaled[train_ind, ]\n",
    "test <- data.scaled[-train_ind, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.bal <- ovun.sample(volact ~ ., data = train, method = \"over\", N = 114264)$data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.X <- train[, -1]\n",
    "train.y <- train[, 1]\n",
    "train.y <- factor(train.y, levels = 0:1)\n",
    "train.X.bal <- train[, -1]\n",
    "train.y.bal <- train[, 1]\n",
    "train.y.bal <- factor(train.y, levels = 0:1)\n",
    "test.X <- test[, -1]\n",
    "test.y <- test[, 1]\n",
    "test.y <- factor(test.y, levels = 0:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC <- function(table){\n",
    "    tp <- table[2,2]\n",
    "    tn <- table[1,1]\n",
    "    fp <- table[2,1]\n",
    "    fn <- table[1,2]\n",
    "    acc <- (tn + tp) / (tn + tp + fn + fp)\n",
    "    return(acc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE <- function(table){\n",
    "    tp <- table[2,2]\n",
    "    tn <- table[1,1]\n",
    "    fp <- table[2,1]\n",
    "    fn <- table[1,2]\n",
    "    PCP <- (tp + tn)/(tp + tn + fp + fn)\n",
    "    PMC <- max(tp + fn, tn + fp)/(tp + tn + fp + fn)\n",
    "    result <- (PCP - PMC)/(1 - PMC)\n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 <- function(table){\n",
    "    tp <- table[2,2]\n",
    "    tn <- table[1,1]\n",
    "    fp <- table[2,1]\n",
    "    fn <- table[1,2]\n",
    "    precision <- tp / (tp + fp)\n",
    "    recall <- tp / (tp + fn)\n",
    "    result <- (2 * precision * recall) / (precision + recall)\n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aus: R deep learning essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aus: R deep learning essentials\n",
    "m20.0 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.1 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0.1),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.2 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0.2),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.3 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0.3),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.4 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0.4),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.5 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0.5),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.6 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0.6),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.7 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0.7),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.8 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0.8),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.9 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0.9),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)\n",
    "m20.10 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 1),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 1000,\n",
    "           maxit = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat20.0 <- predict(m20.0)\n",
    "yhat20.1 <- predict(m20.1)\n",
    "yhat20.2 <- predict(m20.2)\n",
    "yhat20.3 <- predict(m20.3)\n",
    "yhat20.4 <- predict(m20.4)\n",
    "yhat20.5 <- predict(m20.5)\n",
    "yhat20.6 <- predict(m20.6)\n",
    "yhat20.7 <- predict(m20.7)\n",
    "yhat20.8 <- predict(m20.8)\n",
    "yhat20.9 <- predict(m20.9)\n",
    "yhat20.10 <- predict(m20.10)\n",
    "yhat_unseen20.0 <- predict(m20.0, as.matrix(test.X))\n",
    "yhat_unseen20.1 <- predict(m20.1, as.matrix(test.X))\n",
    "yhat_unseen20.2 <- predict(m20.2, as.matrix(test.X))\n",
    "yhat_unseen20.3 <- predict(m20.3, as.matrix(test.X))\n",
    "yhat_unseen20.4 <- predict(m20.4, as.matrix(test.X))\n",
    "yhat_unseen20.5 <- predict(m20.5, as.matrix(test.X))\n",
    "yhat_unseen20.6 <- predict(m20.6, as.matrix(test.X))\n",
    "yhat_unseen20.7 <- predict(m20.7, as.matrix(test.X))\n",
    "yhat_unseen20.8 <- predict(m20.8, as.matrix(test.X))\n",
    "yhat_unseen20.9 <- predict(m20.9, as.matrix(test.X))\n",
    "yhat_unseen20.10 <- predict(m20.10, as.matrix(test.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures <- c(\"AccuracyNull\", \"Accuracy\", \"AccuracyLower\", \"AccuracyUpper\")\n",
    "\n",
    "n20.0.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.0))\n",
    "n20.1.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.1))\n",
    "n20.2.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.2))\n",
    "n20.3.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.3))\n",
    "n20.4.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.4))\n",
    "n20.5.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.5))\n",
    "n20.6.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.6))\n",
    "n20.7.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.7))\n",
    "n20.8.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.8))\n",
    "n20.9.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.9))\n",
    "n20.10.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20.10))\n",
    "n20.0.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.0))\n",
    "n20.1.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.1))\n",
    "n20.2.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.2))\n",
    "n20.3.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.3))\n",
    "n20.4.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.4))\n",
    "n20.5.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.5))\n",
    "n20.6.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.6))\n",
    "n20.7.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.7))\n",
    "n20.8.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.8))\n",
    "n20.9.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.9))\n",
    "n20.10.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20.10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shrinkage <- rbind(\n",
    "  cbind(Size = 20.0, Sample = \"In\", as.data.frame(t(n20.0.insample$overall[measures]))),\n",
    "  cbind(Size = 20.0, Sample = \"Out\", as.data.frame(t(n20.0.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.1, Sample = \"In\", as.data.frame(t(n20.1.insample$overall[measures]))),\n",
    "  cbind(Size = 20.1, Sample = \"Out\", as.data.frame(t(n20.1.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.2, Sample = \"In\", as.data.frame(t(n20.2.insample$overall[measures]))),\n",
    "  cbind(Size = 20.2, Sample = \"Out\", as.data.frame(t(n20.2.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.3, Sample = \"In\", as.data.frame(t(n20.3.insample$overall[measures]))),\n",
    "  cbind(Size = 20.3, Sample = \"Out\", as.data.frame(t(n20.3.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.4, Sample = \"In\", as.data.frame(t(n20.4.insample$overall[measures]))),\n",
    "  cbind(Size = 20.4, Sample = \"Out\", as.data.frame(t(n20.4.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.5, Sample = \"In\", as.data.frame(t(n20.5.insample$overall[measures]))),\n",
    "  cbind(Size = 20.5, Sample = \"Out\", as.data.frame(t(n20.5.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.6, Sample = \"In\", as.data.frame(t(n20.6.insample$overall[measures]))),\n",
    "  cbind(Size = 20.6, Sample = \"Out\", as.data.frame(t(n20.6.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.7, Sample = \"In\", as.data.frame(t(n20.7.insample$overall[measures]))),\n",
    "  cbind(Size = 20.7, Sample = \"Out\", as.data.frame(t(n20.7.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.8, Sample = \"In\", as.data.frame(t(n20.8.insample$overall[measures]))),\n",
    "  cbind(Size = 20.8, Sample = \"Out\", as.data.frame(t(n20.8.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.9, Sample = \"In\", as.data.frame(t(n20.9.insample$overall[measures]))),\n",
    "  cbind(Size = 20.9, Sample = \"Out\", as.data.frame(t(n20.9.outsample$overall[measures]))),\n",
    "  cbind(Size = 20.99, Sample = \"In\", as.data.frame(t(n20.10.insample$overall[measures]))),\n",
    "  cbind(Size = 20.99, Sample = \"Out\", as.data.frame(t(n20.10.outsample$overall[measures])))\n",
    "  )\n",
    "shrinkage$Pkg <- rep(c(\"In\", \"Out\"), 1)\n",
    "\n",
    "dodge <- position_dodge(width=0.4)\n",
    "\n",
    "p.shrinkage <- ggplot(shrinkage, aes(interaction(Size, sep = \" : \"), Accuracy,\n",
    "                      ymin = AccuracyLower, ymax = AccuracyUpper,\n",
    "                      shape = Sample, linetype = Sample)) +\n",
    "  geom_point(size = 2.5, position = dodge) +\n",
    "  geom_errorbar(width = .25, position = dodge) +\n",
    "  xlab(\"\") + ylab(\"Accuracy + 95% CI\") +\n",
    "  theme_classic() +\n",
    "  theme(legend.key.size = unit(1, \"cm\"), legend.position = c(.8, .2))\n",
    "\n",
    "png(\"test_20.png\",\n",
    "    width = 6, height = 6, units = \"in\", res = 600)\n",
    "  print(p.shrinkage)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  126\n",
      "initial  value 75415.583178 \n",
      "iter  10 value 52153.877568\n",
      "iter  20 value 51754.055353\n",
      "iter  30 value 51619.704179\n",
      "iter  40 value 51532.526562\n",
      "iter  50 value 51491.899731\n",
      "iter  60 value 51438.785687\n",
      "iter  70 value 51410.580844\n",
      "iter  80 value 51376.638678\n",
      "iter  90 value 51338.828328\n",
      "iter 100 value 51314.771455\n",
      "final  value 51314.771455 \n",
      "stopped after 100 iterations\n",
      "# weights:  251\n",
      "initial  value 57155.518870 \n",
      "iter  10 value 52061.184901\n",
      "iter  20 value 51594.146760\n",
      "iter  30 value 51428.837685\n",
      "iter  40 value 51356.780532\n",
      "iter  50 value 51249.435599\n",
      "iter  60 value 51192.042495\n",
      "iter  70 value 51133.309915\n",
      "iter  80 value 51054.262882\n",
      "iter  90 value 51018.341720\n",
      "iter 100 value 50975.927799\n",
      "final  value 50975.927799 \n",
      "stopped after 100 iterations\n",
      "# weights:  376\n",
      "initial  value 68330.909556 \n",
      "iter  10 value 51924.190901\n",
      "iter  20 value 51593.909393\n",
      "iter  30 value 51293.164832\n",
      "iter  40 value 51103.736696\n",
      "iter  50 value 51038.082360\n",
      "iter  60 value 50973.967209\n",
      "iter  70 value 50917.594947\n",
      "iter  80 value 50873.557101\n",
      "iter  90 value 50817.286038\n",
      "iter 100 value 50771.658289\n",
      "final  value 50771.658289 \n",
      "stopped after 100 iterations\n",
      "# weights:  501\n",
      "initial  value 122666.791682 \n",
      "iter  10 value 51854.452632\n",
      "iter  20 value 51531.569012\n",
      "iter  30 value 51228.087473\n",
      "iter  40 value 51026.816769\n",
      "iter  50 value 50928.378217\n",
      "iter  60 value 50796.729189\n",
      "iter  70 value 50659.543047\n",
      "iter  80 value 50583.333403\n",
      "iter  90 value 50540.337504\n",
      "iter 100 value 50501.954158\n",
      "final  value 50501.954158 \n",
      "stopped after 100 iterations\n",
      "# weights:  751\n",
      "initial  value 75815.772430 \n",
      "iter  10 value 51833.605414\n",
      "iter  20 value 51463.002683\n",
      "iter  30 value 51168.612418\n",
      "iter  40 value 50990.002029\n",
      "iter  50 value 50822.866923\n",
      "iter  60 value 50670.247701\n",
      "iter  70 value 50554.093487\n",
      "iter  80 value 50474.614568\n",
      "iter  90 value 50385.702794\n",
      "iter 100 value 50300.624732\n",
      "final  value 50300.624732 \n",
      "stopped after 100 iterations\n",
      "# weights:  1001\n",
      "initial  value 64063.803400 \n",
      "iter  10 value 52319.505445\n",
      "iter  20 value 51536.469980\n",
      "iter  30 value 51223.966901\n",
      "iter  40 value 50994.019302\n",
      "iter  50 value 50822.460120\n",
      "iter  60 value 50616.207769\n",
      "iter  70 value 50443.853305\n",
      "iter  80 value 50309.266945\n",
      "iter  90 value 50240.416768\n",
      "iter 100 value 50116.564669\n",
      "final  value 50116.564669 \n",
      "stopped after 100 iterations\n",
      "# weights:  1251\n",
      "initial  value 74744.052312 \n",
      "iter  10 value 52101.346567\n",
      "iter  20 value 51456.542970\n",
      "iter  30 value 51105.693993\n",
      "iter  40 value 50945.584945\n",
      "iter  50 value 50776.752051\n",
      "iter  60 value 50617.253556\n",
      "iter  70 value 50387.727883\n",
      "iter  80 value 50201.231391\n",
      "iter  90 value 50065.893681\n",
      "iter 100 value 49970.551293\n",
      "final  value 49970.551293 \n",
      "stopped after 100 iterations\n",
      "# weights:  1751\n",
      "initial  value 146759.756987 \n",
      "iter  10 value 52036.655050\n",
      "iter  20 value 51454.553594\n",
      "iter  30 value 51001.797352\n",
      "iter  40 value 50715.884164\n",
      "iter  50 value 50516.452631\n",
      "iter  60 value 50299.996400\n",
      "iter  70 value 50129.603957\n",
      "iter  80 value 49970.611044\n",
      "iter  90 value 49758.694945\n",
      "iter 100 value 49571.145635\n",
      "final  value 49571.145635 \n",
      "stopped after 100 iterations\n",
      "# weights:  2501\n",
      "initial  value 97856.882439 \n",
      "iter  10 value 52474.461772\n",
      "iter  20 value 51666.875618\n",
      "iter  30 value 51172.817189\n",
      "iter  40 value 50763.527767\n",
      "iter  50 value 50466.379107\n",
      "iter  60 value 50242.240789\n",
      "iter  70 value 50105.962252\n",
      "iter  80 value 49922.757824\n",
      "iter  90 value 49715.281925\n",
      "iter 100 value 49479.471194\n",
      "final  value 49479.471194 \n",
      "stopped after 100 iterations\n"
     ]
    }
   ],
   "source": [
    "m5 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(5),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 2000,\n",
    "           maxit = 100)\n",
    "m10 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(10),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 2000,\n",
    "           maxit = 100)\n",
    "m15 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(15),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 2000,\n",
    "           maxit = 100)\n",
    "m20 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(20),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 2000,\n",
    "           maxit = 100)\n",
    "m30 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(30),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 2000,\n",
    "           maxit = 100)\n",
    "m40 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(40),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 2000,\n",
    "           maxit = 100)\n",
    "m50 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(50),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 2000,\n",
    "           maxit = 100)\n",
    "m70 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(70),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 2000,\n",
    "           maxit = 100)\n",
    "m100 <- train(x = train.X, y = train.y,\n",
    "           method = \"nnet\", \n",
    "           tuneGrid = expand.grid(\n",
    "           .size = c(100),\n",
    "           .decay = 0),\n",
    "           trControl= trainControl(method = \"none\"),\n",
    "           MaxNWts = 20000,\n",
    "           maxit = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat5 <- predict(m5)\n",
    "yhat10 <- predict(m10)\n",
    "yhat15 <- predict(m15)\n",
    "yhat20 <- predict(m20)\n",
    "yhat30 <- predict(m30)\n",
    "yhat40 <- predict(m40)\n",
    "yhat50 <- predict(m50)\n",
    "yhat70 <- predict(m70)\n",
    "yhat100 <- predict(m100)\n",
    "\n",
    "yhat_unseen5 <- predict(m5, as.matrix(test.X))\n",
    "yhat_unseen10 <- predict(m10, as.matrix(test.X))\n",
    "yhat_unseen15 <- predict(m15, as.matrix(test.X))\n",
    "yhat_unseen20 <- predict(m20, as.matrix(test.X))\n",
    "yhat_unseen30 <- predict(m30, as.matrix(test.X))\n",
    "yhat_unseen40 <- predict(m40, as.matrix(test.X))\n",
    "yhat_unseen50 <- predict(m50, as.matrix(test.X))\n",
    "yhat_unseen70 <- predict(m70, as.matrix(test.X))\n",
    "yhat_unseen100 <- predict(m100, as.matrix(test.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures <- c(\"AccuracyNull\", \"Accuracy\", \"AccuracyLower\", \"AccuracyUpper\")\n",
    "\n",
    "n5.insample <- caret::confusionMatrix(xtabs(~train.y + yhat5))\n",
    "n10.insample <- caret::confusionMatrix(xtabs(~train.y + yhat10))\n",
    "n15.insample <- caret::confusionMatrix(xtabs(~train.y + yhat15))\n",
    "n20.insample <- caret::confusionMatrix(xtabs(~train.y + yhat20))\n",
    "n30.insample <- caret::confusionMatrix(xtabs(~train.y + yhat30))\n",
    "n40.insample <- caret::confusionMatrix(xtabs(~train.y + yhat40))\n",
    "n50.insample <- caret::confusionMatrix(xtabs(~train.y + yhat50))\n",
    "n70.insample <- caret::confusionMatrix(xtabs(~train.y + yhat70))\n",
    "n100.insample <- caret::confusionMatrix(xtabs(~train.y + yhat100))\n",
    "\n",
    "n5.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen5))\n",
    "n10.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen10))\n",
    "n15.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen15))\n",
    "n20.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen20))\n",
    "n30.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen30))\n",
    "n40.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen40))\n",
    "n50.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen50))\n",
    "n70.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen70))\n",
    "n100.outsample <- caret::confusionMatrix(xtabs(~test.y + yhat_unseen100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shrinkage <- rbind(\n",
    "  cbind(Size = 5, Sample = \"In\", as.data.frame(t(n5.insample$overall[measures]))),\n",
    "  cbind(Size = 5, Sample = \"Out\", as.data.frame(t(n5.outsample$overall[measures]))),\n",
    "  cbind(Size = 10, Sample = \"In\", as.data.frame(t(n10.insample$overall[measures]))),\n",
    "  cbind(Size = 10, Sample = \"Out\", as.data.frame(t(n10.outsample$overall[measures]))),\n",
    "  cbind(Size = 15, Sample = \"In\", as.data.frame(t(n15.insample$overall[measures]))),\n",
    "  cbind(Size = 15, Sample = \"Out\", as.data.frame(t(n15.outsample$overall[measures]))),\n",
    "  cbind(Size = 20, Sample = \"In\", as.data.frame(t(n20.insample$overall[measures]))),\n",
    "  cbind(Size = 20, Sample = \"Out\", as.data.frame(t(n20.outsample$overall[measures]))),\n",
    "  cbind(Size = 30, Sample = \"In\", as.data.frame(t(n30.insample$overall[measures]))),\n",
    "  cbind(Size = 30, Sample = \"Out\", as.data.frame(t(n30.outsample$overall[measures]))),\n",
    "  cbind(Size = 40, Sample = \"In\", as.data.frame(t(n40.insample$overall[measures]))),\n",
    "  cbind(Size = 40, Sample = \"Out\", as.data.frame(t(n40.outsample$overall[measures]))),\n",
    "  cbind(Size = 50, Sample = \"In\", as.data.frame(t(n50.insample$overall[measures]))),\n",
    "  cbind(Size = 50, Sample = \"Out\", as.data.frame(t(n50.outsample$overall[measures]))),\n",
    "  cbind(Size = 70, Sample = \"In\", as.data.frame(t(n70.insample$overall[measures]))),\n",
    "  cbind(Size = 70, Sample = \"Out\", as.data.frame(t(n70.outsample$overall[measures]))),\n",
    "  cbind(Size = 100, Sample = \"In\", as.data.frame(t(n100.insample$overall[measures]))),\n",
    "  cbind(Size = 100, Sample = \"Out\", as.data.frame(t(n100.outsample$overall[measures])))\n",
    "  )\n",
    "shrinkage$Pkg <- rep(c(\"In\", \"Out\"), 1)\n",
    "\n",
    "dodge <- position_dodge(width=0.4)\n",
    "\n",
    "p.shrinkage <- ggplot(shrinkage, aes(interaction(Size, sep = \" : \"), Accuracy,\n",
    "                      ymin = AccuracyLower, ymax = AccuracyUpper,\n",
    "                      shape = Sample, linetype = Sample)) +\n",
    "  geom_point(size = 2.5, position = dodge) +\n",
    "  geom_errorbar(width = .25, position = dodge) +\n",
    "  xlab(\"\") + ylab(\"Accuracy + 95% CI\") +\n",
    "  theme_classic() +\n",
    "  theme(legend.key.size = unit(1, \"cm\"), legend.position = c(.8, .2))\n",
    "\n",
    "png(\"test_5150.png\",\n",
    "    width = 6, height = 6, units = \"in\", res = 600)\n",
    "  print(p.shrinkage)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aus h2o deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H2O is not running yet, starting it now...\n",
      "\n",
      "Note:  In case of errors look at the following log files:\n",
      "    C:\\Users\\laris\\AppData\\Local\\Temp\\RtmpkXY0ly/h2o_laris_started_from_r.out\n",
      "    C:\\Users\\laris\\AppData\\Local\\Temp\\RtmpkXY0ly/h2o_laris_started_from_r.err\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: ... Connection successful!\n",
      "\n",
      "R is connected to the H2O cluster: \n",
      "    H2O cluster uptime:         9 seconds 137 milliseconds \n",
      "    H2O cluster timezone:       Europe/Berlin \n",
      "    H2O data parsing timezone:  UTC \n",
      "    H2O cluster version:        3.18.0.8 \n",
      "    H2O cluster version age:    1 month and 11 days  \n",
      "    H2O cluster name:           H2O_started_from_R_laris_exq087 \n",
      "    H2O cluster total nodes:    1 \n",
      "    H2O cluster total memory:   1.66 GB \n",
      "    H2O cluster total cores:    4 \n",
      "    H2O cluster allowed cores:  4 \n",
      "    H2O cluster healthy:        TRUE \n",
      "    H2O Connection ip:          localhost \n",
      "    H2O Connection port:        54321 \n",
      "    H2O Connection proxy:       NA \n",
      "    H2O Internal Security:      FALSE \n",
      "    H2O API Extensions:         Algos, AutoML, Core V3, Core V4 \n",
      "    R Version:                  R version 3.4.1 (2017-06-30) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "c1 <- h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "train$volact <- as.factor(train$volact)\n",
    "test$volact <- as.factor(test$volact)\n",
    "\n",
    "h2o.train <- as.h2o(train)\n",
    "h2o.test <- as.h2o(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.bal$volact <- as.factor(train.bal$volact)\n",
    "h2o.train.bal <- as.h2o(train.bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnames <- colnames(train[,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OAutoEncoderModel: deeplearning\n",
      "Model Key:  DeepLearning_model_R_1527321233701_68 \n",
      "Status of Neuron Layers: auto-encoder, gaussian distribution, Quadratic loss, 922 weights/biases, 17,3 KB, 873.280 training samples, mini-batch size 1\n",
      "  layer units  type dropout       l1       l2 mean_rate rate_rms momentum\n",
      "1     1    22 Input  0.00 %                                              \n",
      "2     2    20  Tanh  0.00 % 0.000000 0.000000  0.037412 0.023002 0.000000\n",
      "3     3    22  Tanh         0.000000 0.000000  0.073935 0.038064 0.000000\n",
      "  mean_weight weight_rms mean_bias bias_rms\n",
      "1                                          \n",
      "2   -0.006882   0.138086 -0.010339 0.031392\n",
      "3   -0.017709   0.391488 -0.006595 0.068448\n",
      "\n",
      "H2OAutoEncoderMetrics: deeplearning\n",
      "** Reported on training data. **\n",
      "\n",
      "Training Set Metrics: \n",
      "=====================\n",
      "\n",
      "MSE: (Extract with `h2o.mse`) 0.000775966\n",
      "RMSE: (Extract with `h2o.rmse`) 0.02785617\n",
      "\n",
      "H2OAutoEncoderMetrics: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "Validation Set Metrics: \n",
      "=====================\n",
      "\n",
      "MSE: (Extract with `h2o.mse`) 0.0007785136\n",
      "RMSE: (Extract with `h2o.rmse`) 0.02790186\n",
      "\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "            timestamp   duration  training_speed   epochs iterations\n",
      "1 2018-05-26 11:22:44  0.381 sec 0,00000 obs/sec  0.00000          0\n",
      "2 2018-05-26 11:22:50  6.421 sec   59055 obs/sec  4.00000          4\n",
      "3 2018-05-26 11:22:56 12.418 sec   59316 obs/sec  8.00000          8\n",
      "4 2018-05-26 11:22:59 15.485 sec   59358 obs/sec 10.00000         10\n",
      "5 2018-05-26 11:22:59 15.605 sec   59346 obs/sec 10.00000         10\n",
      "        samples training_rmse training_mse validation_rmse validation_mse\n",
      "1      0.000000       0.40657      0.16530         0.40715        0.16577\n",
      "2 349312.000000       0.02869      0.00082         0.02865        0.00082\n",
      "3 698624.000000       0.02786      0.00078         0.02790        0.00078\n",
      "4 873280.000000       0.02800      0.00078         0.02808        0.00079\n",
      "5 873280.000000       0.02786      0.00078         0.02790        0.00078\n",
      "\n",
      "Variable Importances: (Extract with `h2o.varimp`) \n",
      "=================================================\n",
      "\n",
      "Variable Importances: \n",
      "          variable relative_importance scaled_importance percentage\n",
      "1      houseperson            1.000000          1.000000   0.074803\n",
      "2            tvpol            0.821404          0.821404   0.061444\n",
      "3 self_realisation            0.764039          0.764039   0.057153\n",
      "4       solidarity            0.753003          0.753003   0.056327\n",
      "5            yrbrn            0.741865          0.741865   0.055494\n",
      "\n",
      "---\n",
      "   variable relative_importance scaled_importance percentage\n",
      "17 children            0.515150          0.515150   0.038535\n",
      "18   female            0.506691          0.506691   0.037902\n",
      "19   round1            0.420082          0.420082   0.031424\n",
      "20  married            0.409787          0.409787   0.030653\n",
      "21   wkhtot            0.147439          0.147439   0.011029\n",
      "22   eduyrs            0.125973          0.125973   0.009423\n",
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OAutoEncoderModel: deeplearning\n",
      "Model Key:  DeepLearning_model_R_1527321233701_69 \n",
      "Status of Neuron Layers: auto-encoder, gaussian distribution, Quadratic loss, 1.127 weights/biases, 20,5 KB, 873.280 training samples, mini-batch size 1\n",
      "  layer units  type dropout       l1       l2 mean_rate rate_rms momentum\n",
      "1     1    22 Input  0.00 %                                              \n",
      "2     2    20  Tanh  0.00 % 0.000000 0.000000  0.046413 0.028715 0.000000\n",
      "3     3    15  Tanh  0.00 % 0.000000 0.000000  0.041075 0.013811 0.000000\n",
      "4     4    22  Tanh         0.000000 0.000000  0.030836 0.024565 0.000000\n",
      "  mean_weight weight_rms mean_bias bias_rms\n",
      "1                                          \n",
      "2    0.012673   0.137722  0.021292 0.051456\n",
      "3   -0.006502   0.199126 -0.011689 0.034189\n",
      "4    0.010531   0.386529 -0.024531 0.038349\n",
      "\n",
      "H2OAutoEncoderMetrics: deeplearning\n",
      "** Reported on training data. **\n",
      "\n",
      "Training Set Metrics: \n",
      "=====================\n",
      "\n",
      "MSE: (Extract with `h2o.mse`) 0.00606855\n",
      "RMSE: (Extract with `h2o.rmse`) 0.0779009\n",
      "\n",
      "H2OAutoEncoderMetrics: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "Validation Set Metrics: \n",
      "=====================\n",
      "\n",
      "MSE: (Extract with `h2o.mse`) 0.006087287\n",
      "RMSE: (Extract with `h2o.rmse`) 0.07802107\n",
      "\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "            timestamp   duration  training_speed   epochs iterations\n",
      "1 2018-05-26 11:23:01  0.517 sec 0,00000 obs/sec  0.00000          0\n",
      "2 2018-05-26 11:23:08  6.870 sec   42337 obs/sec  3.00000          3\n",
      "3 2018-05-26 11:23:13 12.259 sec   45881 obs/sec  6.00000          6\n",
      "4 2018-05-26 11:23:18 17.424 sec   47868 obs/sec  9.00000          9\n",
      "5 2018-05-26 11:23:20 19.260 sec   48258 obs/sec 10.00000         10\n",
      "6 2018-05-26 11:23:20 19.414 sec   48250 obs/sec 10.00000         10\n",
      "        samples training_rmse training_mse validation_rmse validation_mse\n",
      "1      0.000000       0.37986      0.14429         0.37946        0.14399\n",
      "2 261984.000000       0.07819      0.00611         0.07840        0.00615\n",
      "3 523968.000000       0.07825      0.00612         0.07839        0.00615\n",
      "4 785952.000000       0.07790      0.00607         0.07802        0.00609\n",
      "5 873280.000000       0.07792      0.00607         0.07803        0.00609\n",
      "6 873280.000000       0.07790      0.00607         0.07802        0.00609\n",
      "\n",
      "Variable Importances: (Extract with `h2o.varimp`) \n",
      "=================================================\n",
      "\n",
      "Variable Importances: \n",
      "      variable relative_importance scaled_importance percentage\n",
      "1 social_trust            1.000000          1.000000   0.070170\n",
      "2       church            0.980340          0.980340   0.068790\n",
      "3       trstep            0.964037          0.964037   0.067646\n",
      "4      sclmeet            0.928203          0.928203   0.065132\n",
      "5       stfdem            0.924611          0.924611   0.064880\n",
      "\n",
      "---\n",
      "      variable relative_importance scaled_importance percentage\n",
      "17       yrbrn            0.466086          0.466086   0.032705\n",
      "18      round1            0.453203          0.453203   0.031801\n",
      "19   trust_leg            0.426960          0.426960   0.029960\n",
      "20      eduyrs            0.172784          0.172784   0.012124\n",
      "21 houseperson            0.145562          0.145562   0.010214\n",
      "22      wkhtot            0.127275          0.127275   0.008931\n",
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OAutoEncoderModel: deeplearning\n",
      "Model Key:  DeepLearning_model_R_1527321233701_70 \n",
      "Status of Neuron Layers: auto-encoder, gaussian distribution, Quadratic loss, 1.177 weights/biases, 21,8 KB, 873.280 training samples, mini-batch size 1\n",
      "  layer units  type dropout       l1       l2 mean_rate rate_rms momentum\n",
      "1     1    22 Input  0.00 %                                              \n",
      "2     2    20  Tanh  0.00 % 0.000000 0.000000  0.050717 0.026346 0.000000\n",
      "3     3    15  Tanh  0.00 % 0.000000 0.000000  0.043348 0.013814 0.000000\n",
      "4     4    10  Tanh  0.00 % 0.000000 0.000000  0.025917 0.006957 0.000000\n",
      "5     5    22  Tanh         0.000000 0.000000  0.017540 0.016759 0.000000\n",
      "  mean_weight weight_rms mean_bias bias_rms\n",
      "1                                          \n",
      "2   -0.007040   0.132461  0.005690 0.039503\n",
      "3    0.016562   0.202858  0.010925 0.030090\n",
      "4   -0.012409   0.195769  0.000497 0.038236\n",
      "5    0.029514   0.431324 -0.031500 0.056378\n",
      "\n",
      "H2OAutoEncoderMetrics: deeplearning\n",
      "** Reported on training data. **\n",
      "\n",
      "Training Set Metrics: \n",
      "=====================\n",
      "\n",
      "MSE: (Extract with `h2o.mse`) 0.0146455\n",
      "RMSE: (Extract with `h2o.rmse`) 0.1210186\n",
      "\n",
      "H2OAutoEncoderMetrics: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "Validation Set Metrics: \n",
      "=====================\n",
      "\n",
      "MSE: (Extract with `h2o.mse`) 0.01472278\n",
      "RMSE: (Extract with `h2o.rmse`) 0.1213375\n",
      "\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "            timestamp   duration  training_speed   epochs iterations\n",
      "1 2018-05-26 11:23:22  0.596 sec 0,00000 obs/sec  0.00000          0\n",
      "2 2018-05-26 11:23:29  7.450 sec   39260 obs/sec  3.00000          3\n",
      "3 2018-05-26 11:23:35 13.408 sec   42106 obs/sec  6.00000          6\n",
      "4 2018-05-26 11:23:41 19.219 sec   43485 obs/sec  9.00000          9\n",
      "5 2018-05-26 11:23:43 21.278 sec   43758 obs/sec 10.00000         10\n",
      "6 2018-05-26 11:23:43 21.426 sec   43751 obs/sec 10.00000         10\n",
      "        samples training_rmse training_mse validation_rmse validation_mse\n",
      "1      0.000000       0.35621      0.12689         0.35593        0.12668\n",
      "2 261984.000000       0.12102      0.01465         0.12134        0.01472\n",
      "3 523968.000000       0.12144      0.01475         0.12179        0.01483\n",
      "4 785952.000000       0.12138      0.01473         0.12166        0.01480\n",
      "5 873280.000000       0.12165      0.01480         0.12198        0.01488\n",
      "6 873280.000000       0.12102      0.01465         0.12134        0.01472\n",
      "\n",
      "Variable Importances: (Extract with `h2o.varimp`) \n",
      "=================================================\n",
      "\n",
      "Variable Importances: \n",
      "  variable relative_importance scaled_importance percentage\n",
      "1   round1            1.000000          1.000000   0.074355\n",
      "2 children            0.992962          0.992962   0.073832\n",
      "3   church            0.990690          0.990690   0.073663\n",
      "4  domicil            0.990034          0.990034   0.073614\n",
      "5   female            0.966728          0.966728   0.071881\n",
      "\n",
      "---\n",
      "           variable relative_importance scaled_importance percentage\n",
      "17        tolerance            0.387960          0.387960   0.028847\n",
      "18 self_realisation            0.320136          0.320136   0.023804\n",
      "19      houseperson            0.308317          0.308317   0.022925\n",
      "20           eduyrs            0.307930          0.307930   0.022896\n",
      "21     social_trust            0.239737          0.239737   0.017826\n",
      "22           wkhtot            0.228089          0.228089   0.016960\n",
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OAutoEncoderModel: deeplearning\n",
      "Model Key:  DeepLearning_model_R_1527321233701_71 \n",
      "Status of Neuron Layers: auto-encoder, gaussian distribution, Quadratic loss, 1.122 weights/biases, 21,8 KB, 873.280 training samples, mini-batch size 1\n",
      "  layer units  type dropout       l1       l2 mean_rate rate_rms momentum\n",
      "1     1    22 Input  0.00 %                                              \n",
      "2     2    20  Tanh  0.00 % 0.000000 0.000000  0.250500 0.156754 0.000000\n",
      "3     3    15  Tanh  0.00 % 0.000000 0.000000  0.140612 0.073508 0.000000\n",
      "4     4    10  Tanh  0.00 % 0.000000 0.000000  0.068041 0.040162 0.000000\n",
      "5     5     5  Tanh  0.00 % 0.000000 0.000000  0.015953 0.006296 0.000000\n",
      "6     6    22  Tanh         0.000000 0.000000  0.010988 0.011900 0.000000\n",
      "  mean_weight weight_rms mean_bias bias_rms\n",
      "1                                          \n",
      "2    0.005524   0.219513  0.007912 0.071470\n",
      "3    0.007786   0.249784 -0.055526 0.150431\n",
      "4    0.012745   0.246407  0.042017 0.081458\n",
      "5   -0.025121   0.153236 -0.026973 0.046084\n",
      "6    0.120538   0.574990 -0.011829 0.061625\n",
      "\n",
      "H2OAutoEncoderMetrics: deeplearning\n",
      "** Reported on training data. **\n",
      "\n",
      "Training Set Metrics: \n",
      "=====================\n",
      "\n",
      "MSE: (Extract with `h2o.mse`) 0.03321477\n",
      "RMSE: (Extract with `h2o.rmse`) 0.1822492\n",
      "\n",
      "H2OAutoEncoderMetrics: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "Validation Set Metrics: \n",
      "=====================\n",
      "\n",
      "MSE: (Extract with `h2o.mse`) 0.03327318\n",
      "RMSE: (Extract with `h2o.rmse`) 0.1824094\n",
      "\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "            timestamp   duration  training_speed   epochs iterations\n",
      "1 2018-05-26 11:23:44  0.524 sec 0,00000 obs/sec  0.00000          0\n",
      "2 2018-05-26 11:23:50  6.273 sec   47212 obs/sec  3.00000          3\n",
      "3 2018-05-26 11:23:56 12.052 sec   47094 obs/sec  6.00000          6\n",
      "4 2018-05-26 11:24:02 17.865 sec   46939 obs/sec  9.00000          9\n",
      "5 2018-05-26 11:24:04 19.897 sec   46968 obs/sec 10.00000         10\n",
      "6 2018-05-26 11:24:04 20.082 sec   46968 obs/sec 10.00000         10\n",
      "        samples training_rmse training_mse validation_rmse validation_mse\n",
      "1      0.000000       0.35309      0.12467         0.35224        0.12408\n",
      "2 261984.000000       0.18227      0.03322         0.18254        0.03332\n",
      "3 523968.000000       0.18225      0.03321         0.18241        0.03327\n",
      "4 785952.000000       0.18246      0.03329         0.18271        0.03338\n",
      "5 873280.000000       0.18226      0.03322         0.18242        0.03328\n",
      "6 873280.000000       0.18225      0.03321         0.18241        0.03327\n",
      "\n",
      "Variable Importances: (Extract with `h2o.varimp`) \n",
      "=================================================\n",
      "\n",
      "Variable Importances: \n",
      "   variable relative_importance scaled_importance percentage\n",
      "1    round1            1.000000          1.000000   0.133137\n",
      "2  children            0.783734          0.783734   0.104344\n",
      "3   married            0.769189          0.769189   0.102407\n",
      "4    female            0.632390          0.632390   0.084194\n",
      "5 trust_leg            0.423697          0.423697   0.056410\n",
      "\n",
      "---\n",
      "           variable relative_importance scaled_importance percentage\n",
      "17       solidarity            0.135933          0.135933   0.018098\n",
      "18      houseperson            0.114584          0.114584   0.015255\n",
      "19          domicil            0.111697          0.111697   0.014871\n",
      "20           wkhtot            0.104820          0.104820   0.013955\n",
      "21        tolerance            0.102602          0.102602   0.013660\n",
      "22 self_realisation            0.078634          0.078634   0.010469\n"
     ]
    }
   ],
   "source": [
    "m2a <- h2o.deeplearning(\n",
    "  x = xnames,\n",
    "  #y = \"Outcome\",\n",
    "  training_frame= h2o.train,\n",
    "  validation_frame = h2o.test,\n",
    "  activation = \"Tanh\",\n",
    "  autoencoder = TRUE,\n",
    "  hidden = c(20),\n",
    "  epochs = 10,\n",
    "  sparsity_beta = 0,\n",
    "  l1 = 0,\n",
    "  l2 = 0\n",
    ")\n",
    "\n",
    "m2b <- h2o.deeplearning(\n",
    "  x = xnames,\n",
    "  #y = \"Outcome\",\n",
    "  training_frame= h2o.train,\n",
    "  validation_frame = h2o.test,\n",
    "  activation = \"Tanh\",\n",
    "  autoencoder = TRUE,\n",
    "  hidden = c(20, 15),\n",
    "  epochs = 10,\n",
    "  sparsity_beta = 0,\n",
    "  #hidden_pout_ratios = c(.3),\n",
    "  l1 = 0,\n",
    "  l2 = 0\n",
    ")\n",
    "\n",
    "m2c <- h2o.deeplearning(\n",
    "  x = xnames,\n",
    "  #y = \"Outcome\",\n",
    "  training_frame= h2o.train,\n",
    "  validation_frame = h2o.test,\n",
    "  activation = \"Tanh\",\n",
    "  autoencoder = TRUE,\n",
    "  hidden = c(20, 15, 10),\n",
    "  epochs = 10,\n",
    "  sparsity_beta = 0,\n",
    "  l1 = 0,\n",
    "  l2 = 0\n",
    ")\n",
    "\n",
    "m2d <- h2o.deeplearning(\n",
    "  x = xnames,\n",
    "  #y = \"Outcome\",\n",
    "  training_frame= h2o.train,\n",
    "  validation_frame = h2o.test,\n",
    "  activation = \"Tanh\",\n",
    "  autoencoder = TRUE,\n",
    "  hidden = c(20, 15, 10, 5),\n",
    "  epochs = 10,\n",
    "  sparsity_beta = 0,\n",
    "  #hi2den_dropout_ratios = c(.3),\n",
    "  l1 = 0,\n",
    "  l2 = 0\n",
    ")\n",
    "\n",
    "summary(m2a)\n",
    "summary(m2b)\n",
    "summary(m2c)\n",
    "summary(m2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAPFBMVEUAAAAaGhozMzNNTU1o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\ngQGJsQUGJMYW2P8BnpaR6GCNFMwAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error1 <- as.data.frame(h2o.anomaly(m2a, h2o.train))\n",
    "error2a <- as.data.frame(h2o.anomaly(m2b, h2o.train))\n",
    "error2b <- as.data.frame(h2o.anomaly(m2c, h2o.train))\n",
    "error2c <- as.data.frame(h2o.anomaly(m2d, h2o.train))\n",
    "\n",
    "error <- as.data.table(rbind(\n",
    "  cbind.data.frame(Model = \"2a\", error1),\n",
    "  cbind.data.frame(Model = \"2b\", error2a),\n",
    "  cbind.data.frame(Model = \"2c\", error2b),\n",
    "  cbind.data.frame(Model = \"2d\", error2c)))\n",
    "\n",
    "percentile <- error[, .(\n",
    "  Percentile = quantile(Reconstruction.MSE, probs = .95)\n",
    "), by = Model]\n",
    "\n",
    "p1 <- ggplot(error, aes(Reconstruction.MSE)) +\n",
    "  geom_histogram(binwidth = .001, fill = \"grey50\") +\n",
    "  geom_vline(aes(xintercept = Percentile), data = percentile, linetype = 2) +\n",
    "  theme_bw() +\n",
    "  facet_wrap(~Model)\n",
    "print(p1)\n",
    "\n",
    "png(\"error_1.png\",\n",
    "    width = 5.5, height = 5.5, units = \"in\", res = 600)\n",
    "print(p1)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OBinomialModel: deeplearning\n",
      "Model Key:  DeepLearning_model_R_1527776472963_1 \n",
      "Status of Neuron Layers: predicting volact, 2-class classification, bernoulli distribution, CrossEntropy loss, 65.102 weights/biases, 776,2 KB, 890.175 training samples, mini-batch size 1\n",
      "  layer units      type dropout       l1       l2 mean_rate rate_rms momentum\n",
      "1     1    22     Input  0.00 %                                              \n",
      "2     2   200 Rectifier  0.00 % 0.000000 0.000000  0.039764 0.015742 0.000000\n",
      "3     3   200 Rectifier  0.00 % 0.000000 0.000000  0.016766 0.008441 0.000000\n",
      "4     4   100 Rectifier  0.00 % 0.000000 0.000000  0.038317 0.059579 0.000000\n",
      "5     5     2   Softmax         0.000000 0.000000  0.009294 0.003672 0.000000\n",
      "  mean_weight weight_rms mean_bias bias_rms\n",
      "1                                          \n",
      "2    0.014879   0.189256  0.239910 0.105072\n",
      "3   -0.027969   0.072399  0.916157 0.085171\n",
      "4   -0.007734   0.084521 -0.171398 0.231650\n",
      "5    0.037996   0.392254 -0.007552 0.190833\n",
      "\n",
      "H2OBinomialMetrics: deeplearning\n",
      "** Reported on training data. **\n",
      "** Metrics reported on temporary training frame with 9951 samples **\n",
      "\n",
      "MSE:  0.2033251\n",
      "RMSE:  0.4509158\n",
      "LogLoss:  0.5922762\n",
      "Mean Per-Class Error:  0.362356\n",
      "AUC:  0.6977062\n",
      "Gini:  0.3954123\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "          0    1    Error        Rate\n",
      "0      3216 3254 0.502937  =3254/6470\n",
      "1       772 2709 0.221775   =772/3481\n",
      "Totals 3988 5963 0.404582  =4026/9951\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.261312 0.573698 254\n",
      "2                       max f2  0.118690 0.739042 353\n",
      "3                 max f0point5  0.392081 0.524875 168\n",
      "4                 max accuracy  0.446425 0.685258 135\n",
      "5                max precision  0.758793 0.833333   2\n",
      "6                   max recall  0.028360 1.000000 397\n",
      "7              max specificity  0.770680 0.999845   0\n",
      "8             max absolute_mcc  0.338839 0.280619 205\n",
      "9   max min_per_class_accuracy  0.328516 0.643431 212\n",
      "10 max mean_per_class_accuracy  0.338839 0.645828 205\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "H2OBinomialMetrics: deeplearning\n",
      "** Reported on validation data. **\n",
      "** Metrics reported on full validation frame **\n",
      "\n",
      "MSE:  0.206565\n",
      "RMSE:  0.4544943\n",
      "LogLoss:  0.6004164\n",
      "Mean Per-Class Error:  0.374573\n",
      "AUC:  0.6943986\n",
      "Gini:  0.3887972\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "          0    1    Error        Rate\n",
      "0      2584 3637 0.584633  =3637/6221\n",
      "1       573 2910 0.164513   =573/3483\n",
      "Totals 3157 6547 0.433842  =4210/9704\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.226878 0.580259 273\n",
      "2                       max f2  0.133590 0.742003 336\n",
      "3                 max f0point5  0.395150 0.528468 164\n",
      "4                 max accuracy  0.461671 0.682502 123\n",
      "5                max precision  0.772056 1.000000   0\n",
      "6                   max recall  0.019996 1.000000 398\n",
      "7              max specificity  0.772056 1.000000   0\n",
      "8             max absolute_mcc  0.315137 0.267794 216\n",
      "9   max min_per_class_accuracy  0.327404 0.638000 208\n",
      "10 max mean_per_class_accuracy  0.315137 0.639543 216\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "            timestamp          duration training_speed   epochs iterations\n",
      "1 2018-05-31 16:22:53         0.000 sec                 0.00000          0\n",
      "2 2018-05-31 16:23:02        13.456 sec   5220 obs/sec  0.51295          1\n",
      "3 2018-05-31 16:23:35        45.398 sec   8136 obs/sec  3.56884          7\n",
      "4 2018-05-31 16:23:59  1 min  9.592 sec   8831 obs/sec  6.11594         12\n",
      "5 2018-05-31 16:24:23  1 min 32.740 sec   9238 obs/sec  8.66777         17\n",
      "6 2018-05-31 16:24:37  1 min 47.144 sec   9442 obs/sec 10.19347         20\n",
      "7 2018-05-31 16:24:39  1 min 48.883 sec   9433 obs/sec 10.19347         20\n",
      "        samples training_rmse training_logloss training_auc training_lift\n",
      "1      0.000000                                                          \n",
      "2  44795.000000       0.46057          0.61415      0.68349       2.22976\n",
      "3 311660.000000       0.45092          0.59228      0.69771       2.20117\n",
      "4 534093.000000       0.44930          0.58807      0.70971       2.14400\n",
      "5 756939.000000       0.44624          0.58254      0.71522       2.14400\n",
      "6 890175.000000       0.44292          0.57384      0.72476       2.25834\n",
      "7 890175.000000       0.45092          0.59228      0.69771       2.20117\n",
      "  training_classification_error validation_rmse validation_logloss\n",
      "1                                                                 \n",
      "2                       0.45242         0.46320            0.62055\n",
      "3                       0.40458         0.45449            0.60042\n",
      "4                       0.41011         0.45603            0.60420\n",
      "5                       0.40177         0.45541            0.60444\n",
      "6                       0.38790         0.45404            0.60102\n",
      "7                       0.40458         0.45449            0.60042\n",
      "  validation_auc validation_lift validation_classification_error\n",
      "1                                                               \n",
      "2        0.68628         2.24594                         0.43250\n",
      "3        0.69440         2.16065                         0.43384\n",
      "4        0.69482         2.24594                         0.41612\n",
      "5        0.69331         2.27437                         0.45383\n",
      "6        0.69448         2.27437                         0.42745\n",
      "7        0.69440         2.16065                         0.43384\n",
      "\n",
      "Variable Importances: (Extract with `h2o.varimp`) \n",
      "=================================================\n",
      "\n",
      "Variable Importances: \n",
      "      variable relative_importance scaled_importance percentage\n",
      "1       eduyrs            1.000000          1.000000   0.071032\n",
      "2       round1            0.939375          0.939375   0.066725\n",
      "3 social_trust            0.854368          0.854368   0.060687\n",
      "4       church            0.821406          0.821406   0.058346\n",
      "5      sclmeet            0.788391          0.788391   0.056001\n",
      "\n",
      "---\n",
      "           variable relative_importance scaled_importance percentage\n",
      "17        tolerance            0.476803          0.476803   0.033868\n",
      "18           trstep            0.458310          0.458310   0.032555\n",
      "19 self_realisation            0.457716          0.457716   0.032512\n",
      "20           stfdem            0.454999          0.454999   0.032319\n",
      "21      houseperson            0.447639          0.447639   0.031797\n",
      "22           wkhtot            0.402998          0.402998   0.028626\n"
     ]
    }
   ],
   "source": [
    "#in sample = 0.70\n",
    "mt3 <- h2o.deeplearning(\n",
    "  x = xnames,\n",
    "  y = \"volact\",\n",
    "  training_frame = h2o.train,\n",
    "  validation_frame = h2o.test,\n",
    "  activation = \"Rectifier\",\n",
    "  hidden = c(200, 200, 100),\n",
    "  epochs = 10,\n",
    "  rate = .005,\n",
    "  loss = \"CrossEntropy\",\n",
    "  #input_dropout_ratio = .2,\n",
    "  #hidden_dropout_ratios = c(.5, .3, .1),\n",
    "  export_weights_and_biases = TRUE\n",
    ")\n",
    "summary(mt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.588726298433636"
      ],
      "text/latex": [
       "0.588726298433636"
      ],
      "text/markdown": [
       "0.588726298433636"
      ],
      "text/plain": [
       "[1] 0.5887263"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.145851277634223"
      ],
      "text/latex": [
       "-0.145851277634223"
      ],
      "text/markdown": [
       "-0.145851277634223"
      ],
      "text/plain": [
       "[1] -0.1458513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.581524588445004"
      ],
      "text/latex": [
       "0.581524588445004"
      ],
      "text/markdown": [
       "0.581524588445004"
      ],
      "text/plain": [
       "[1] 0.5815246"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mt3_pred <- h2o.predict(mt3, h2o.test)\n",
    "ACC(table(as.vector(mt3_pred$predict), as.vector(h2o.test$volact)))\n",
    "PRE(table(as.vector(mt3_pred$predict), as.vector(h2o.test$volact)))\n",
    "F1(table(as.vector(mt3_pred$predict), as.vector(h2o.test$volact)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>variable</th><th scope=col>relative_importance</th><th scope=col>scaled_importance</th><th scope=col>percentage</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>eduyrs            </td><td>1.0000000         </td><td>1.0000000         </td><td>0.06786655        </td></tr>\n",
       "\t<tr><td>yrbrn             </td><td>0.9774464         </td><td>0.9774464         </td><td>0.06633592        </td></tr>\n",
       "\t<tr><td>round1            </td><td>0.9719231         </td><td>0.9719231         </td><td>0.06596107        </td></tr>\n",
       "\t<tr><td>sclmeet           </td><td>0.8775737         </td><td>0.8775737         </td><td>0.05955790        </td></tr>\n",
       "\t<tr><td>social_trust      </td><td>0.8170829         </td><td>0.8170829         </td><td>0.05545260        </td></tr>\n",
       "\t<tr><td>church            </td><td>0.7512495         </td><td>0.7512495         </td><td>0.05098471        </td></tr>\n",
       "\t<tr><td>tvpol             </td><td>0.7493991         </td><td>0.7493991         </td><td>0.05085914        </td></tr>\n",
       "\t<tr><td>trust_exe         </td><td>0.7223423         </td><td>0.7223423         </td><td>0.04902288        </td></tr>\n",
       "\t<tr><td>political_interest</td><td>0.7104195         </td><td>0.7104195         </td><td>0.04821373        </td></tr>\n",
       "\t<tr><td>married           </td><td>0.6410848         </td><td>0.6410848         </td><td>0.04350822        </td></tr>\n",
       "\t<tr><td>trust_leg         </td><td>0.6237921         </td><td>0.6237921         </td><td>0.04233462        </td></tr>\n",
       "\t<tr><td>tvtot             </td><td>0.6090486         </td><td>0.6090486         </td><td>0.04133403        </td></tr>\n",
       "\t<tr><td>solidarity        </td><td>0.6037391         </td><td>0.6037391         </td><td>0.04097369        </td></tr>\n",
       "\t<tr><td>female            </td><td>0.5928637         </td><td>0.5928637         </td><td>0.04023561        </td></tr>\n",
       "\t<tr><td>children          </td><td>0.5897075         </td><td>0.5897075         </td><td>0.04002142        </td></tr>\n",
       "\t<tr><td>stfdem            </td><td>0.5735353         </td><td>0.5735353         </td><td>0.03892386        </td></tr>\n",
       "\t<tr><td>domicil           </td><td>0.5478558         </td><td>0.5478558         </td><td>0.03718108        </td></tr>\n",
       "\t<tr><td>wkhtot            </td><td>0.5427228         </td><td>0.5427228         </td><td>0.03683273        </td></tr>\n",
       "\t<tr><td>tolerance         </td><td>0.4959922         </td><td>0.4959922         </td><td>0.03366128        </td></tr>\n",
       "\t<tr><td>trstep            </td><td>0.4879771         </td><td>0.4879771         </td><td>0.03311732        </td></tr>\n",
       "\t<tr><td>houseperson       </td><td>0.4250491         </td><td>0.4250491         </td><td>0.02884662        </td></tr>\n",
       "\t<tr><td>self_realisation  </td><td>0.4239941         </td><td>0.4239941         </td><td>0.02877502        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " variable & relative\\_importance & scaled\\_importance & percentage\\\\\n",
       "\\hline\n",
       "\t eduyrs             & 1.0000000          & 1.0000000          & 0.06786655        \\\\\n",
       "\t yrbrn              & 0.9774464          & 0.9774464          & 0.06633592        \\\\\n",
       "\t round1             & 0.9719231          & 0.9719231          & 0.06596107        \\\\\n",
       "\t sclmeet            & 0.8775737          & 0.8775737          & 0.05955790        \\\\\n",
       "\t social\\_trust       & 0.8170829            & 0.8170829            & 0.05545260          \\\\\n",
       "\t church             & 0.7512495          & 0.7512495          & 0.05098471        \\\\\n",
       "\t tvpol              & 0.7493991          & 0.7493991          & 0.05085914        \\\\\n",
       "\t trust\\_exe          & 0.7223423            & 0.7223423            & 0.04902288          \\\\\n",
       "\t political\\_interest & 0.7104195            & 0.7104195            & 0.04821373          \\\\\n",
       "\t married            & 0.6410848          & 0.6410848          & 0.04350822        \\\\\n",
       "\t trust\\_leg          & 0.6237921            & 0.6237921            & 0.04233462          \\\\\n",
       "\t tvtot              & 0.6090486          & 0.6090486          & 0.04133403        \\\\\n",
       "\t solidarity         & 0.6037391          & 0.6037391          & 0.04097369        \\\\\n",
       "\t female             & 0.5928637          & 0.5928637          & 0.04023561        \\\\\n",
       "\t children           & 0.5897075          & 0.5897075          & 0.04002142        \\\\\n",
       "\t stfdem             & 0.5735353          & 0.5735353          & 0.03892386        \\\\\n",
       "\t domicil            & 0.5478558          & 0.5478558          & 0.03718108        \\\\\n",
       "\t wkhtot             & 0.5427228          & 0.5427228          & 0.03683273        \\\\\n",
       "\t tolerance          & 0.4959922          & 0.4959922          & 0.03366128        \\\\\n",
       "\t trstep             & 0.4879771          & 0.4879771          & 0.03311732        \\\\\n",
       "\t houseperson        & 0.4250491          & 0.4250491          & 0.02884662        \\\\\n",
       "\t self\\_realisation   & 0.4239941            & 0.4239941            & 0.02877502          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "variable | relative_importance | scaled_importance | percentage | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| eduyrs             | 1.0000000          | 1.0000000          | 0.06786655         | \n",
       "| yrbrn              | 0.9774464          | 0.9774464          | 0.06633592         | \n",
       "| round1             | 0.9719231          | 0.9719231          | 0.06596107         | \n",
       "| sclmeet            | 0.8775737          | 0.8775737          | 0.05955790         | \n",
       "| social_trust       | 0.8170829          | 0.8170829          | 0.05545260         | \n",
       "| church             | 0.7512495          | 0.7512495          | 0.05098471         | \n",
       "| tvpol              | 0.7493991          | 0.7493991          | 0.05085914         | \n",
       "| trust_exe          | 0.7223423          | 0.7223423          | 0.04902288         | \n",
       "| political_interest | 0.7104195          | 0.7104195          | 0.04821373         | \n",
       "| married            | 0.6410848          | 0.6410848          | 0.04350822         | \n",
       "| trust_leg          | 0.6237921          | 0.6237921          | 0.04233462         | \n",
       "| tvtot              | 0.6090486          | 0.6090486          | 0.04133403         | \n",
       "| solidarity         | 0.6037391          | 0.6037391          | 0.04097369         | \n",
       "| female             | 0.5928637          | 0.5928637          | 0.04023561         | \n",
       "| children           | 0.5897075          | 0.5897075          | 0.04002142         | \n",
       "| stfdem             | 0.5735353          | 0.5735353          | 0.03892386         | \n",
       "| domicil            | 0.5478558          | 0.5478558          | 0.03718108         | \n",
       "| wkhtot             | 0.5427228          | 0.5427228          | 0.03683273         | \n",
       "| tolerance          | 0.4959922          | 0.4959922          | 0.03366128         | \n",
       "| trstep             | 0.4879771          | 0.4879771          | 0.03311732         | \n",
       "| houseperson        | 0.4250491          | 0.4250491          | 0.02884662         | \n",
       "| self_realisation   | 0.4239941          | 0.4239941          | 0.02877502         | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   variable           relative_importance scaled_importance percentage\n",
       "1  eduyrs             1.0000000           1.0000000         0.06786655\n",
       "2  yrbrn              0.9774464           0.9774464         0.06633592\n",
       "3  round1             0.9719231           0.9719231         0.06596107\n",
       "4  sclmeet            0.8775737           0.8775737         0.05955790\n",
       "5  social_trust       0.8170829           0.8170829         0.05545260\n",
       "6  church             0.7512495           0.7512495         0.05098471\n",
       "7  tvpol              0.7493991           0.7493991         0.05085914\n",
       "8  trust_exe          0.7223423           0.7223423         0.04902288\n",
       "9  political_interest 0.7104195           0.7104195         0.04821373\n",
       "10 married            0.6410848           0.6410848         0.04350822\n",
       "11 trust_leg          0.6237921           0.6237921         0.04233462\n",
       "12 tvtot              0.6090486           0.6090486         0.04133403\n",
       "13 solidarity         0.6037391           0.6037391         0.04097369\n",
       "14 female             0.5928637           0.5928637         0.04023561\n",
       "15 children           0.5897075           0.5897075         0.04002142\n",
       "16 stfdem             0.5735353           0.5735353         0.03892386\n",
       "17 domicil            0.5478558           0.5478558         0.03718108\n",
       "18 wkhtot             0.5427228           0.5427228         0.03683273\n",
       "19 tolerance          0.4959922           0.4959922         0.03366128\n",
       "20 trstep             0.4879771           0.4879771         0.03311732\n",
       "21 houseperson        0.4250491           0.4250491         0.02884662\n",
       "22 self_realisation   0.4239941           0.4239941         0.02877502"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.varimp(mt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OBinomialModel: deeplearning\n",
      "Model Key:  DeepLearning_model_R_1527753908592_365 \n",
      "Status of Neuron Layers: predicting volact, 2-class classification, bernoulli distribution, CrossEntropy loss, 65.102 weights/biases, 776,2 KB, 1.157.574 training samples, mini-batch size 1\n",
      "  layer units      type dropout       l1       l2 mean_rate rate_rms momentum\n",
      "1     1    22     Input  0.00 %                                              \n",
      "2     2   200 Rectifier  0.00 % 0.000000 0.000000  0.004992 0.001929 0.000000\n",
      "3     3   200 Rectifier  0.00 % 0.000000 0.000000  0.005542 0.004359 0.000000\n",
      "4     4   100 Rectifier  0.00 % 0.000000 0.000000  0.037032 0.046162 0.000000\n",
      "5     5     2   Softmax         0.000000 0.000000  0.005273 0.002752 0.000000\n",
      "  mean_weight weight_rms mean_bias bias_rms\n",
      "1                                          \n",
      "2    0.040592   0.249749  0.011312 0.145901\n",
      "3   -0.043690   0.103730  0.805847 0.203119\n",
      "4   -0.005882   0.100125 -0.278733 0.513060\n",
      "5   -0.034293   0.408039  0.084470 0.832530\n",
      "\n",
      "H2OBinomialMetrics: deeplearning\n",
      "** Reported on training data. **\n",
      "** Metrics reported on temporary training frame with 10108 samples **\n",
      "\n",
      "MSE:  0.2467354\n",
      "RMSE:  0.4967246\n",
      "LogLoss:  0.6974706\n",
      "Mean Per-Class Error:  0.3038732\n",
      "AUC:  0.7802905\n",
      "Gini:  0.560581\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "          0    1    Error         Rate\n",
      "0      2506 2511 0.500498   =2511/5017\n",
      "1       546 4545 0.107248    =546/5091\n",
      "Totals 3052 7056 0.302434  =3057/10108\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.141994 0.748333 315\n",
      "2                       max f2  0.059975 0.860593 362\n",
      "3                 max f0point5  0.271499 0.709536 245\n",
      "4                 max accuracy  0.220350 0.709438 273\n",
      "5                max precision  0.957331 1.000000   0\n",
      "6                   max recall  0.006663 1.000000 395\n",
      "7              max specificity  0.957331 1.000000   0\n",
      "8             max absolute_mcc  0.149439 0.428473 311\n",
      "9   max min_per_class_accuracy  0.269504 0.705202 246\n",
      "10 max mean_per_class_accuracy  0.220350 0.708855 273\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "H2OBinomialMetrics: deeplearning\n",
      "** Reported on validation data. **\n",
      "** Metrics reported on full validation frame **\n",
      "\n",
      "MSE:  0.2249117\n",
      "RMSE:  0.4742486\n",
      "LogLoss:  0.6897646\n",
      "Mean Per-Class Error:  0.3927145\n",
      "AUC:  0.6767033\n",
      "Gini:  0.3534066\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "          0    1    Error        Rate\n",
      "0      2369 3852 0.619193  =3852/6221\n",
      "1       579 2904 0.166236   =579/3483\n",
      "Totals 2948 6756 0.456616  =4431/9704\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.107819 0.567243 321\n",
      "2                       max f2  0.006793 0.738432 394\n",
      "3                 max f0point5  0.345462 0.519408 182\n",
      "4                 max accuracy  0.398566 0.670136 148\n",
      "5                max precision  0.926309 0.750000   3\n",
      "6                   max recall  0.000822 1.000000 399\n",
      "7              max specificity  0.969560 0.999839   0\n",
      "8             max absolute_mcc  0.242378 0.251879 242\n",
      "9   max min_per_class_accuracy  0.245840 0.629917 240\n",
      "10 max mean_per_class_accuracy  0.218833 0.631173 256\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "            timestamp          duration training_speed   epochs iterations\n",
      "1 2018-05-31 12:33:48         0.000 sec                 0.00000          0\n",
      "2 2018-05-31 12:33:56        10.119 sec   5794 obs/sec  0.42204          1\n",
      "3 2018-05-31 12:34:13        26.903 sec   8142 obs/sec  1.68745          4\n",
      "4 2018-05-31 12:34:29        43.081 sec   8815 obs/sec  2.95500          7\n",
      "5 2018-05-31 12:34:45        59.018 sec   9161 obs/sec  4.22064         10\n",
      "6 2018-05-31 12:35:05  1 min 18.849 sec   9561 obs/sec  5.91140         14\n",
      "7 2018-05-31 12:35:24  1 min 37.617 sec   9869 obs/sec  7.60196         18\n",
      "8 2018-05-31 12:35:39  1 min 52.533 sec   9983 obs/sec  8.86626         21\n",
      "9 2018-05-31 12:35:53  2 min  7.380 sec  10087 obs/sec 10.13070         24\n",
      "         samples training_rmse training_logloss training_auc training_lift\n",
      "1       0.000000                                                          \n",
      "2   48224.000000       0.70969          7.10697      0.68282       1.73242\n",
      "3  192815.000000       0.70408          2.58590      0.69978       1.82974\n",
      "4  337650.000000       0.70433          5.26280      0.68040       1.42645\n",
      "5  482267.000000       0.70969          8.65918      0.45704       1.24578\n",
      "6  675460.000000       0.70151          2.44032      0.72052       1.67402\n",
      "7  868630.000000       0.48960          0.68251      0.75260       1.75188\n",
      "8 1013094.000000       0.45557          0.60247      0.77079       1.81028\n",
      "9 1157574.000000       0.49672          0.69747      0.78029       1.79081\n",
      "  training_classification_error validation_rmse validation_logloss\n",
      "1                                                                 \n",
      "2                       0.38524         0.59910            5.07039\n",
      "3                       0.38158         0.59448            1.85842\n",
      "4                       0.39592         0.80045            6.81629\n",
      "5                       0.49634         0.59910            6.21230\n",
      "6                       0.34250         0.59265            1.79305\n",
      "7                       0.31925         0.56012            0.85926\n",
      "8                       0.31124         0.52105            0.75585\n",
      "9                       0.30243         0.47425            0.68976\n",
      "  validation_auc validation_lift validation_classification_error\n",
      "1                                                               \n",
      "2        0.67956         2.10379                         0.43013\n",
      "3        0.68927         2.01850                         0.43436\n",
      "4        0.66316         1.81950                         0.48784\n",
      "5        0.44808         1.22247                         0.64108\n",
      "6        0.68560         2.13222                         0.41983\n",
      "7        0.68116         2.18908                         0.43096\n",
      "8        0.67566         2.01850                         0.43869\n",
      "9        0.67670         1.99007                         0.45662\n",
      "\n",
      "Variable Importances: (Extract with `h2o.varimp`) \n",
      "=================================================\n",
      "\n",
      "Variable Importances: \n",
      "      variable relative_importance scaled_importance percentage\n",
      "1       eduyrs            1.000000          1.000000   0.065642\n",
      "2        yrbrn            0.872927          0.872927   0.057301\n",
      "3      sclmeet            0.868932          0.868932   0.057039\n",
      "4 social_trust            0.834624          0.834624   0.054786\n",
      "5       round1            0.805814          0.805814   0.052895\n",
      "\n",
      "---\n",
      "      variable relative_importance scaled_importance percentage\n",
      "17  solidarity            0.585702          0.585702   0.038447\n",
      "18      wkhtot            0.584021          0.584021   0.038336\n",
      "19      trstep            0.580937          0.580937   0.038134\n",
      "20   tolerance            0.580659          0.580659   0.038116\n",
      "21       tvtot            0.579382          0.579382   0.038032\n",
      "22 houseperson            0.526330          0.526330   0.034549\n"
     ]
    }
   ],
   "source": [
    "#balanced training set\n",
    "mtbal <- h2o.deeplearning(\n",
    "  x = xnames,\n",
    "  y = \"volact\",\n",
    "  training_frame = h2o.train.bal,\n",
    "  validation_frame = h2o.test,\n",
    "  activation = \"Rectifier\",\n",
    "  hidden = c(200, 200, 100),\n",
    "  epochs = 10,\n",
    "  rate = .005,\n",
    "  loss = \"CrossEntropy\",\n",
    "  #input_dropout_ratio = .2,\n",
    "  #hidden_dropout_ratios = c(.5, .3, .1),\n",
    "  export_weights_and_biases = TRUE\n",
    ")\n",
    "summary(mtbal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.54338417147568"
      ],
      "text/latex": [
       "0.54338417147568"
      ],
      "text/markdown": [
       "0.54338417147568"
      ],
      "text/plain": [
       "[1] 0.5433842"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.272179155900086"
      ],
      "text/latex": [
       "-0.272179155900086"
      ],
      "text/markdown": [
       "-0.272179155900086"
      ],
      "text/plain": [
       "[1] -0.2721792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.566735112936345"
      ],
      "text/latex": [
       "0.566735112936345"
      ],
      "text/markdown": [
       "0.566735112936345"
      ],
      "text/plain": [
       "[1] 0.5667351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mtbal_pred <- h2o.predict(mtbal, h2o.test)\n",
    "ACC(table(as.vector(mtbal_pred$predict), as.vector(h2o.test$volact)))\n",
    "PRE(table(as.vector(mtbal_pred$predict), as.vector(h2o.test$volact)))\n",
    "F1(table(as.vector(mtbal_pred$predict), as.vector(h2o.test$volact)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>variable</th><th scope=col>relative_importance</th><th scope=col>scaled_importance</th><th scope=col>percentage</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>eduyrs            </td><td>1.0000000         </td><td>1.0000000         </td><td>0.07137106        </td></tr>\n",
       "\t<tr><td>round1            </td><td>0.9554664         </td><td>0.9554664         </td><td>0.06819266        </td></tr>\n",
       "\t<tr><td>yrbrn             </td><td>0.7707927         </td><td>0.7707927         </td><td>0.05501230        </td></tr>\n",
       "\t<tr><td>church            </td><td>0.7557535         </td><td>0.7557535         </td><td>0.05393893        </td></tr>\n",
       "\t<tr><td>social_trust      </td><td>0.7368259         </td><td>0.7368259         </td><td>0.05258805        </td></tr>\n",
       "\t<tr><td>tvpol             </td><td>0.7180524         </td><td>0.7180524         </td><td>0.05124816        </td></tr>\n",
       "\t<tr><td>political_interest</td><td>0.7118363         </td><td>0.7118363         </td><td>0.05080452        </td></tr>\n",
       "\t<tr><td>sclmeet           </td><td>0.7048413         </td><td>0.7048413         </td><td>0.05030527        </td></tr>\n",
       "\t<tr><td>trust_exe         </td><td>0.7023646         </td><td>0.7023646         </td><td>0.05012851        </td></tr>\n",
       "\t<tr><td>stfdem            </td><td>0.6119521         </td><td>0.6119521         </td><td>0.04367567        </td></tr>\n",
       "\t<tr><td>tvtot             </td><td>0.6005091         </td><td>0.6005091         </td><td>0.04285897        </td></tr>\n",
       "\t<tr><td>trust_leg         </td><td>0.5993351         </td><td>0.5993351         </td><td>0.04277519        </td></tr>\n",
       "\t<tr><td>trstep            </td><td>0.5935599         </td><td>0.5935599         </td><td>0.04236300        </td></tr>\n",
       "\t<tr><td>female            </td><td>0.5792335         </td><td>0.5792335         </td><td>0.04134051        </td></tr>\n",
       "\t<tr><td>married           </td><td>0.5532824         </td><td>0.5532824         </td><td>0.03948836        </td></tr>\n",
       "\t<tr><td>domicil           </td><td>0.5515640         </td><td>0.5515640         </td><td>0.03936571        </td></tr>\n",
       "\t<tr><td>children          </td><td>0.5398210         </td><td>0.5398210         </td><td>0.03852760        </td></tr>\n",
       "\t<tr><td>solidarity        </td><td>0.5361080         </td><td>0.5361080         </td><td>0.03826260        </td></tr>\n",
       "\t<tr><td>self_realisation  </td><td>0.5000473         </td><td>0.5000473         </td><td>0.03568890        </td></tr>\n",
       "\t<tr><td>wkhtot            </td><td>0.4431857         </td><td>0.4431857         </td><td>0.03163064        </td></tr>\n",
       "\t<tr><td>tolerance         </td><td>0.4380509         </td><td>0.4380509         </td><td>0.03126416        </td></tr>\n",
       "\t<tr><td>houseperson       </td><td>0.4086986         </td><td>0.4086986         </td><td>0.02916925        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " variable & relative\\_importance & scaled\\_importance & percentage\\\\\n",
       "\\hline\n",
       "\t eduyrs             & 1.0000000          & 1.0000000          & 0.07137106        \\\\\n",
       "\t round1             & 0.9554664          & 0.9554664          & 0.06819266        \\\\\n",
       "\t yrbrn              & 0.7707927          & 0.7707927          & 0.05501230        \\\\\n",
       "\t church             & 0.7557535          & 0.7557535          & 0.05393893        \\\\\n",
       "\t social\\_trust       & 0.7368259            & 0.7368259            & 0.05258805          \\\\\n",
       "\t tvpol              & 0.7180524          & 0.7180524          & 0.05124816        \\\\\n",
       "\t political\\_interest & 0.7118363            & 0.7118363            & 0.05080452          \\\\\n",
       "\t sclmeet            & 0.7048413          & 0.7048413          & 0.05030527        \\\\\n",
       "\t trust\\_exe          & 0.7023646            & 0.7023646            & 0.05012851          \\\\\n",
       "\t stfdem             & 0.6119521          & 0.6119521          & 0.04367567        \\\\\n",
       "\t tvtot              & 0.6005091          & 0.6005091          & 0.04285897        \\\\\n",
       "\t trust\\_leg          & 0.5993351            & 0.5993351            & 0.04277519          \\\\\n",
       "\t trstep             & 0.5935599          & 0.5935599          & 0.04236300        \\\\\n",
       "\t female             & 0.5792335          & 0.5792335          & 0.04134051        \\\\\n",
       "\t married            & 0.5532824          & 0.5532824          & 0.03948836        \\\\\n",
       "\t domicil            & 0.5515640          & 0.5515640          & 0.03936571        \\\\\n",
       "\t children           & 0.5398210          & 0.5398210          & 0.03852760        \\\\\n",
       "\t solidarity         & 0.5361080          & 0.5361080          & 0.03826260        \\\\\n",
       "\t self\\_realisation   & 0.5000473            & 0.5000473            & 0.03568890          \\\\\n",
       "\t wkhtot             & 0.4431857          & 0.4431857          & 0.03163064        \\\\\n",
       "\t tolerance          & 0.4380509          & 0.4380509          & 0.03126416        \\\\\n",
       "\t houseperson        & 0.4086986          & 0.4086986          & 0.02916925        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "variable | relative_importance | scaled_importance | percentage | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| eduyrs             | 1.0000000          | 1.0000000          | 0.07137106         | \n",
       "| round1             | 0.9554664          | 0.9554664          | 0.06819266         | \n",
       "| yrbrn              | 0.7707927          | 0.7707927          | 0.05501230         | \n",
       "| church             | 0.7557535          | 0.7557535          | 0.05393893         | \n",
       "| social_trust       | 0.7368259          | 0.7368259          | 0.05258805         | \n",
       "| tvpol              | 0.7180524          | 0.7180524          | 0.05124816         | \n",
       "| political_interest | 0.7118363          | 0.7118363          | 0.05080452         | \n",
       "| sclmeet            | 0.7048413          | 0.7048413          | 0.05030527         | \n",
       "| trust_exe          | 0.7023646          | 0.7023646          | 0.05012851         | \n",
       "| stfdem             | 0.6119521          | 0.6119521          | 0.04367567         | \n",
       "| tvtot              | 0.6005091          | 0.6005091          | 0.04285897         | \n",
       "| trust_leg          | 0.5993351          | 0.5993351          | 0.04277519         | \n",
       "| trstep             | 0.5935599          | 0.5935599          | 0.04236300         | \n",
       "| female             | 0.5792335          | 0.5792335          | 0.04134051         | \n",
       "| married            | 0.5532824          | 0.5532824          | 0.03948836         | \n",
       "| domicil            | 0.5515640          | 0.5515640          | 0.03936571         | \n",
       "| children           | 0.5398210          | 0.5398210          | 0.03852760         | \n",
       "| solidarity         | 0.5361080          | 0.5361080          | 0.03826260         | \n",
       "| self_realisation   | 0.5000473          | 0.5000473          | 0.03568890         | \n",
       "| wkhtot             | 0.4431857          | 0.4431857          | 0.03163064         | \n",
       "| tolerance          | 0.4380509          | 0.4380509          | 0.03126416         | \n",
       "| houseperson        | 0.4086986          | 0.4086986          | 0.02916925         | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   variable           relative_importance scaled_importance percentage\n",
       "1  eduyrs             1.0000000           1.0000000         0.07137106\n",
       "2  round1             0.9554664           0.9554664         0.06819266\n",
       "3  yrbrn              0.7707927           0.7707927         0.05501230\n",
       "4  church             0.7557535           0.7557535         0.05393893\n",
       "5  social_trust       0.7368259           0.7368259         0.05258805\n",
       "6  tvpol              0.7180524           0.7180524         0.05124816\n",
       "7  political_interest 0.7118363           0.7118363         0.05080452\n",
       "8  sclmeet            0.7048413           0.7048413         0.05030527\n",
       "9  trust_exe          0.7023646           0.7023646         0.05012851\n",
       "10 stfdem             0.6119521           0.6119521         0.04367567\n",
       "11 tvtot              0.6005091           0.6005091         0.04285897\n",
       "12 trust_leg          0.5993351           0.5993351         0.04277519\n",
       "13 trstep             0.5935599           0.5935599         0.04236300\n",
       "14 female             0.5792335           0.5792335         0.04134051\n",
       "15 married            0.5532824           0.5532824         0.03948836\n",
       "16 domicil            0.5515640           0.5515640         0.03936571\n",
       "17 children           0.5398210           0.5398210         0.03852760\n",
       "18 solidarity         0.5361080           0.5361080         0.03826260\n",
       "19 self_realisation   0.5000473           0.5000473         0.03568890\n",
       "20 wkhtot             0.4431857           0.4431857         0.03163064\n",
       "21 tolerance          0.4380509           0.4380509         0.03126416\n",
       "22 houseperson        0.4086986           0.4086986         0.02916925"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.varimp(mtbal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nwBH/D6i1VnAbhLqzAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## weights for mapping from inputs to hidden layer 1 neurons\n",
    "w1 <- as.matrix(h2o.weights(mtbal, 1))\n",
    "\n",
    "## plot heatmap of the weights\n",
    "tmp <- as.data.frame(t(w1))\n",
    "tmp$Row <- 1:nrow(tmp)\n",
    "tmp <- melt(tmp, id.vars = c(\"Row\"))\n",
    "\n",
    "p.heat <- ggplot(tmp,\n",
    "       aes(variable, Row, fill = value)) +\n",
    "  geom_tile() +\n",
    "  scale_fill_gradientn(colours = c(\"black\", \"white\", \"blue\")) +\n",
    "  theme_classic() +\n",
    "  theme(axis.text = element_blank()) +\n",
    "  xlab(\"Hidden Neuron\") +\n",
    "  ylab(\"Input Variable\") +\n",
    "  ggtitle(\"Heatmap of Weights for Layer 1\")\n",
    "print(p.heat)\n",
    "\n",
    "png(\"heatmap_layer1.png\",\n",
    "    width = 5.5, height = 7.5, units = \"in\", res = 600)\n",
    "print(p.heat)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OBinomialModel: drf\n",
      "Model Key:  forest2 \n",
      "Model Summary: \n",
      "  number_of_trees number_of_internal_trees model_size_in_bytes min_depth\n",
      "1             400                      400            88854137        30\n",
      "  max_depth mean_depth min_leaves max_leaves mean_leaves\n",
      "1        30   30.00000      17362      17955 17694.77000\n",
      "\n",
      "H2OBinomialMetrics: drf\n",
      "** Reported on training data. **\n",
      "** Metrics reported on Out-Of-Bag training samples **\n",
      "\n",
      "MSE:  0.2018624\n",
      "RMSE:  0.449291\n",
      "LogLoss:  0.5890251\n",
      "Mean Per-Class Error:  0.3630926\n",
      "AUC:  0.6968135\n",
      "Gini:  0.3936271\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "           0     1    Error          Rate\n",
      "0      29048 28137 0.492035  =28137/57185\n",
      "1       7058 23085 0.234151   =7058/30143\n",
      "Totals 36106 51222 0.403021  =35195/87328\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.310361 0.567443 244\n",
      "2                       max f2  0.173625 0.732855 335\n",
      "3                 max f0point5  0.416304 0.523857 174\n",
      "4                 max accuracy  0.491262 0.687179 127\n",
      "5                max precision  0.885550 1.000000   0\n",
      "6                   max recall  0.021040 1.000000 398\n",
      "7              max specificity  0.885550 1.000000   0\n",
      "8             max absolute_mcc  0.386625 0.276972 193\n",
      "9   max min_per_class_accuracy  0.362091 0.643234 211\n",
      "10 max mean_per_class_accuracy  0.357833 0.644492 214\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "H2OBinomialMetrics: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE:  0.2040188\n",
      "RMSE:  0.4516844\n",
      "LogLoss:  0.5936523\n",
      "Mean Per-Class Error:  0.3670008\n",
      "AUC:  0.7023226\n",
      "Gini:  0.4046452\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "          0    1    Error        Rate\n",
      "0      2680 3541 0.569201  =3541/6221\n",
      "1       574 2909 0.164800   =574/3483\n",
      "Totals 3254 6450 0.424052  =4115/9704\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.281044 0.585724 270\n",
      "2                       max f2  0.196677 0.746586 331\n",
      "3                 max f0point5  0.403085 0.535334 177\n",
      "4                 max accuracy  0.486682 0.686521 120\n",
      "5                max precision  0.808905 0.833333   3\n",
      "6                   max recall  0.058872 1.000000 395\n",
      "7              max specificity  0.854773 0.999839   0\n",
      "8             max absolute_mcc  0.371348 0.280079 201\n",
      "9   max min_per_class_accuracy  0.362428 0.642340 208\n",
      "10 max mean_per_class_accuracy  0.347422 0.645130 219\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "             timestamp          duration number_of_trees training_rmse\n",
      "1  2018-05-31 16:57:26         0.193 sec               0              \n",
      "2  2018-05-31 16:57:29         3.526 sec               1       0.63668\n",
      "3  2018-05-31 16:57:35        10.004 sec               6       0.55801\n",
      "4  2018-05-31 16:57:40        14.630 sec              11       0.51196\n",
      "5  2018-05-31 16:57:45        19.158 sec              17       0.48751\n",
      "6  2018-05-31 16:57:49        23.207 sec              24       0.47546\n",
      "7  2018-05-31 16:57:53        27.699 sec              30       0.46928\n",
      "8  2018-05-31 16:57:58        32.685 sec              38       0.46424\n",
      "9  2018-05-31 16:58:04        38.872 sec              47       0.46107\n",
      "10 2018-05-31 16:58:13        47.348 sec              58       0.45856\n",
      "11 2018-05-31 16:58:23        57.158 sec              71       0.45645\n",
      "12 2018-05-31 16:58:35  1 min  9.577 sec              90       0.45449\n",
      "13 2018-05-31 16:58:53  1 min 27.100 sec             117       0.45304\n",
      "14 2018-05-31 16:59:17  1 min 51.237 sec             156       0.45172\n",
      "15 2018-05-31 16:59:54  2 min 28.910 sec             217       0.45054\n",
      "16 2018-05-31 17:00:54  3 min 28.662 sec             313       0.44967\n",
      "17 2018-05-31 17:01:55  4 min 29.228 sec             400       0.44929\n",
      "   training_logloss training_auc training_lift training_classification_error\n",
      "1                                                                           \n",
      "2          13.92970      0.55654       1.20357                       0.65391\n",
      "3           7.31875      0.57828       1.28779                       0.65437\n",
      "4           3.66926      0.60410       1.38890                       0.50814\n",
      "5           1.87775      0.62305       1.52821                       0.51315\n",
      "6           1.13999      0.63578       1.80582                       0.49727\n",
      "7           0.88242      0.64480       1.82859                       0.49895\n",
      "8           0.74389      0.65438       1.94213                       0.47795\n",
      "9           0.68080      0.66110       1.95604                       0.47693\n",
      "10          0.64091      0.66693       2.00147                       0.44264\n",
      "11          0.61816      0.67248       2.06275                       0.43957\n",
      "12          0.60554      0.67855       2.04903                       0.43814\n",
      "13          0.60073      0.68327       2.09163                       0.44205\n",
      "14          0.59588      0.68771       2.13072                       0.43031\n",
      "15          0.59199      0.69198       2.15461                       0.41719\n",
      "16          0.58977      0.69532       2.20102                       0.40935\n",
      "17          0.58903      0.69681       2.15631                       0.40302\n",
      "   validation_rmse validation_logloss validation_auc validation_lift\n",
      "1                                                                   \n",
      "2          0.64272           14.20689        0.54767         1.17262\n",
      "3          0.48947            1.60581        0.61763         1.66041\n",
      "4          0.47221            0.83927        0.64372         1.84502\n",
      "5          0.46515            0.67604        0.65743         2.10379\n",
      "6          0.46063            0.62379        0.66925         2.07536\n",
      "7          0.45829            0.61531        0.67726         2.18908\n",
      "8          0.45723            0.60628        0.67982         2.10603\n",
      "9          0.45580            0.60338        0.68499         2.10379\n",
      "10         0.45459            0.60055        0.68936         2.11538\n",
      "11         0.45396            0.59890        0.69196         2.12040\n",
      "12         0.45366            0.59810        0.69366         2.04693\n",
      "13         0.45360            0.59809        0.69431         1.99007\n",
      "14         0.45306            0.59674        0.69670         1.99007\n",
      "15         0.45249            0.59540        0.69894         1.99007\n",
      "16         0.45194            0.59421        0.70112         2.10379\n",
      "17         0.45168            0.59365        0.70232         2.01850\n",
      "   validation_classification_error\n",
      "1                                 \n",
      "2                          0.64108\n",
      "3                          0.56853\n",
      "4                          0.47867\n",
      "5                          0.49969\n",
      "6                          0.44724\n",
      "7                          0.43240\n",
      "8                          0.46558\n",
      "9                          0.43003\n",
      "10                         0.42797\n",
      "11                         0.40859\n",
      "12                         0.41406\n",
      "13                         0.41447\n",
      "14                         0.41921\n",
      "15                         0.41282\n",
      "16                         0.40684\n",
      "17                         0.42405\n",
      "\n",
      "Variable Importances: (Extract with `h2o.varimp`) \n",
      "=================================================\n",
      "\n",
      "Variable Importances: \n",
      "      variable relative_importance scaled_importance percentage\n",
      "1        yrbrn       418924.625000          1.000000   0.083222\n",
      "2 social_trust       407513.843750          0.972762   0.080955\n",
      "3       eduyrs       387813.218750          0.925735   0.077042\n",
      "4    trust_exe       357274.468750          0.852837   0.070975\n",
      "5    trust_leg       344703.406250          0.822829   0.068478\n",
      "\n",
      "---\n",
      "             variable relative_importance scaled_importance percentage\n",
      "17 political_interest       166074.687500          0.396431   0.032992\n",
      "18             female        84818.453125          0.202467   0.016850\n",
      "19             round1        80491.187500          0.192138   0.015990\n",
      "20            married        78069.343750          0.186357   0.015509\n",
      "21           children        76684.570312          0.183051   0.015234\n",
      "22        houseperson        24138.466797          0.057620   0.004795\n"
     ]
    }
   ],
   "source": [
    "rf2 <- h2o.randomForest(        \n",
    "  training_frame = h2o.train,        \n",
    "  validation_frame = h2o.test,      \n",
    "  x = xnames,                        \n",
    "  y = \"volact\",                          \n",
    "  model_id = \"forest2\",    \n",
    "  ntrees = 400,            \n",
    "  max_depth = 30,\n",
    "  stopping_rounds = 0,           \n",
    "  score_each_iteration = F,     \n",
    "  seed = 1000000) \n",
    "summary(rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.578318219291014"
      ],
      "text/latex": [
       "0.578318219291014"
      ],
      "text/markdown": [
       "0.578318219291014"
      ],
      "text/plain": [
       "[1] 0.5783182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.174849267872524"
      ],
      "text/latex": [
       "-0.174849267872524"
      ],
      "text/markdown": [
       "-0.174849267872524"
      ],
      "text/plain": [
       "[1] -0.1748493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.585158150851582"
      ],
      "text/latex": [
       "0.585158150851582"
      ],
      "text/markdown": [
       "0.585158150851582"
      ],
      "text/plain": [
       "[1] 0.5851582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf2_pred <- h2o.predict(rf2, h2o.test)\n",
    "ACC(table(as.vector(rf2_pred$predict), as.vector(h2o.test$volact)))\n",
    "PRE(table(as.vector(rf2_pred$predict), as.vector(h2o.test$volact)))\n",
    "F1(table(as.vector(rf2_pred$predict), as.vector(h2o.test$volact)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "Model Details:\n",
      "==============\n",
      "\n",
      "H2OBinomialModel: drf\n",
      "Model Key:  forestbal \n",
      "Model Summary: \n",
      "  number_of_trees number_of_internal_trees model_size_in_bytes min_depth\n",
      "1             400                      400            97219005        30\n",
      "  max_depth mean_depth min_leaves max_leaves mean_leaves\n",
      "1        30   30.00000      18989      19677 19364.53500\n",
      "\n",
      "H2OBinomialMetrics: drf\n",
      "** Reported on training data. **\n",
      "** Metrics reported on Out-Of-Bag training samples **\n",
      "\n",
      "MSE:  0.09830158\n",
      "RMSE:  0.3135308\n",
      "LogLoss:  0.3311802\n",
      "Mean Per-Class Error:  0.08044977\n",
      "AUC:  0.9533665\n",
      "Gini:  0.9067329\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "           0     1    Error          Rate\n",
      "0      56098  1087 0.019008   =1087/57185\n",
      "1       8099 48980 0.141891   =8099/57079\n",
      "Totals 64197 50067 0.080393  =9186/114264\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.644820 0.914267 155\n",
      "2                       max f2  0.452047 0.896443 225\n",
      "3                 max f0point5  0.682220 0.955403 143\n",
      "4                 max accuracy  0.644820 0.919607 155\n",
      "5                max precision  0.999922 1.000000   0\n",
      "6                   max recall  0.043650 1.000000 396\n",
      "7              max specificity  0.999922 1.000000   0\n",
      "8             max absolute_mcc  0.656706 0.846196 151\n",
      "9   max min_per_class_accuracy  0.515047 0.892070 199\n",
      "10 max mean_per_class_accuracy  0.644820 0.919550 155\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "H2OBinomialMetrics: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE:  0.2039317\n",
      "RMSE:  0.4515879\n",
      "LogLoss:  0.5935544\n",
      "Mean Per-Class Error:  0.3658193\n",
      "AUC:  0.7023405\n",
      "Gini:  0.404681\n",
      "\n",
      "Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n",
      "          0    1    Error        Rate\n",
      "0      2759 3462 0.556502  =3462/6221\n",
      "1       610 2873 0.175136   =610/3483\n",
      "Totals 3369 6335 0.419621  =4072/9704\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "                        metric threshold    value idx\n",
      "1                       max f1  0.297605 0.585252 266\n",
      "2                       max f2  0.204977 0.747124 330\n",
      "3                 max f0point5  0.450966 0.542741 152\n",
      "4                 max accuracy  0.474795 0.684563 135\n",
      "5                max precision  0.876521 1.000000   0\n",
      "6                   max recall  0.067713 1.000000 393\n",
      "7              max specificity  0.876521 1.000000   0\n",
      "8             max absolute_mcc  0.450966 0.278696 152\n",
      "9   max min_per_class_accuracy  0.371139 0.639966 210\n",
      "10 max mean_per_class_accuracy  0.358533 0.644849 220\n",
      "\n",
      "Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n",
      "\n",
      "\n",
      "Scoring History: \n",
      "            timestamp   duration number_of_trees training_rmse training_logloss\n",
      "1 2018-05-31 14:01:09  0.053 sec               0                               \n",
      "2 2018-05-31 14:01:11  1.885 sec               1       0.50078          8.55309\n",
      "3 2018-05-31 14:01:12  2.837 sec               2       0.48272          7.36673\n",
      "4 2018-05-31 14:01:13  3.535 sec               3       0.46622          6.33399\n",
      "5 2018-05-31 14:01:13  4.206 sec               4       0.45169          5.45511\n",
      "  training_auc training_lift training_classification_error validation_rmse\n",
      "1                                                                         \n",
      "2      0.74838       1.43275                       0.25216         0.64344\n",
      "3      0.76760       1.48022                       0.24116         0.55532\n",
      "4      0.78542       1.52369                       0.23196         0.52366\n",
      "5      0.80072       1.57016                       0.22419         0.50441\n",
      "  validation_logloss validation_auc validation_lift\n",
      "1                                                  \n",
      "2           14.15371        0.55070         1.17040\n",
      "3            7.20633        0.57858         1.38195\n",
      "4            4.26296        0.59314         1.49654\n",
      "5            2.70377        0.60865         1.61214\n",
      "  validation_classification_error\n",
      "1                                \n",
      "2                         0.64108\n",
      "3                         0.64108\n",
      "4                         0.64108\n",
      "5                         0.53153\n",
      "\n",
      "---\n",
      "             timestamp          duration number_of_trees training_rmse\n",
      "16 2018-05-31 14:02:50  1 min 40.960 sec             134       0.31689\n",
      "17 2018-05-31 14:03:19  2 min  9.912 sec             170       0.31590\n",
      "18 2018-05-31 14:03:53  2 min 43.664 sec             215       0.31500\n",
      "19 2018-05-31 14:04:50  3 min 41.031 sec             287       0.31411\n",
      "20 2018-05-31 14:06:13  5 min  4.262 sec             397       0.31354\n",
      "21 2018-05-31 14:06:28  5 min 19.375 sec             400       0.31353\n",
      "   training_logloss training_auc training_lift training_classification_error\n",
      "16          0.33475      0.95070       2.00186                       0.08760\n",
      "17          0.33353      0.95156       2.00186                       0.08523\n",
      "18          0.33260      0.95219       2.00186                       0.08312\n",
      "19          0.33164      0.95292       2.00186                       0.08199\n",
      "20          0.33118      0.95334       2.00186                       0.08038\n",
      "21          0.33118      0.95337       2.00186                       0.08039\n",
      "   validation_rmse validation_logloss validation_auc validation_lift\n",
      "16         0.45260            0.59573        0.69741         2.13883\n",
      "17         0.45224            0.59509        0.69930         2.10379\n",
      "18         0.45210            0.59468        0.70009         1.99007\n",
      "19         0.45195            0.59432        0.70085         2.01850\n",
      "20         0.45157            0.59352        0.70238         2.04693\n",
      "21         0.45159            0.59355        0.70234         2.01850\n",
      "   validation_classification_error\n",
      "16                         0.40808\n",
      "17                         0.41900\n",
      "18                         0.41921\n",
      "19                         0.43281\n",
      "20                         0.42024\n",
      "21                         0.41962\n",
      "\n",
      "Variable Importances: (Extract with `h2o.varimp`) \n",
      "=================================================\n",
      "\n",
      "Variable Importances: \n",
      "      variable relative_importance scaled_importance percentage\n",
      "1        yrbrn       602631.375000          1.000000   0.082588\n",
      "2 social_trust       598686.375000          0.993454   0.082048\n",
      "3       eduyrs       561575.125000          0.931872   0.076962\n",
      "4    trust_exe       518403.968750          0.860234   0.071045\n",
      "5    trust_leg       501221.562500          0.831722   0.068690\n",
      "\n",
      "---\n",
      "             variable relative_importance scaled_importance percentage\n",
      "17 political_interest       249502.750000          0.414022   0.034193\n",
      "18            married       128836.968750          0.213791   0.017657\n",
      "19             female       121112.570312          0.200973   0.016598\n",
      "20             round1       117152.593750          0.194402   0.016055\n",
      "21           children       110519.945312          0.183396   0.015146\n",
      "22        houseperson        33290.671875          0.055242   0.004562\n"
     ]
    }
   ],
   "source": [
    "rfbal <- h2o.randomForest(        \n",
    "  training_frame = h2o.train.bal,        \n",
    "  validation_frame = h2o.test,      \n",
    "  x = xnames,                        \n",
    "  y = \"volact\",                          \n",
    "  model_id = \"forestbal\",    \n",
    "  ntrees = 400,            \n",
    "  max_depth = 30,\n",
    "  stopping_rounds = 0,           \n",
    "  score_each_iteration = F,     \n",
    "  seed = 1000000) \n",
    "summary(rfbal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.581203627370157"
      ],
      "text/latex": [
       "0.581203627370157"
      ],
      "text/markdown": [
       "0.581203627370157"
      ],
      "text/plain": [
       "[1] 0.5812036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.166810221073787"
      ],
      "text/latex": [
       "-0.166810221073787"
      ],
      "text/markdown": [
       "-0.166810221073787"
      ],
      "text/plain": [
       "[1] -0.1668102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.58530612244898"
      ],
      "text/latex": [
       "0.58530612244898"
      ],
      "text/markdown": [
       "0.58530612244898"
      ],
      "text/plain": [
       "[1] 0.5853061"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfbal_pred <- h2o.predict(rfbal, h2o.test)\n",
    "ACC(table(as.vector(rfbal_pred$predict), as.vector(h2o.test$volact)))\n",
    "PRE(table(as.vector(rfbal_pred$predict), as.vector(h2o.test$volact)))\n",
    "F1(table(as.vector(rfbal_pred$predict), as.vector(h2o.test$volact)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    rue\n",
       "pred    0    1\n",
       "   0 2685  582\n",
       "   1 3536 2901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf2_pred <- h2o.predict(rf2, h2o.test)\n",
    "table(\"pred\"=as.vector(rf2_pred$predict), \"rue\"=as.vector(h2o.test$volact))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corrplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in corrplot(res, type = \"upper\", order = \"hclust\", tl.col = \"black\", : konnte Funktion \"corrplot\" nicht finden\n",
     "execution_count": 1,
     "output_type": "error",
     "traceback": [
      "Error in corrplot(res, type = \"upper\", order = \"hclust\", tl.col = \"black\", : konnte Funktion \"corrplot\" nicht finden\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "png(\"corrplot.png\", width = 5.5, height = 5.5, units = \"in\", res = 600)\n",
    "c <- corrplot(res, type = \"upper\", order = \"hclust\", tl.col = \"black\", tl.srt = 45)\n",
    "dev.off()\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## marginal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "range <- seq(-4, 2, length.out = 20)\n",
    "sel <- 7\n",
    "plot.data <- matrix(NA, nrow = length(range), ncol = ncol(test[,-1]))\n",
    "for(i in 2:ncol(test)){\n",
    "    plot.data[,i-1] <- mean(test[,i])\n",
    "}\n",
    "for(i in 1:length(range)){\n",
    "    plot.data[i, sel] <- range[i]\n",
    "}\n",
    "colnames(plot.data) <- xnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "h2o.plot <- as.h2o(plot.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "mt3_pred <- h2o.predict(mt3, h2o.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn <- data.frame(cbind(range, as.vector(mt3_pred$p1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAAAP8zMzNNTU1o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\nqP8B3zIlWhR++T0AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "png(\"nn-age-volact.png\")\n",
    "myplot <- ggplot(df_nn,aes(x = df_nn[,1], y = df_nn[,2], ymin = 0, ymax = 0)) + \n",
    "    geom_pointrange(col = \"blue\") + \n",
    "    ylab(\"Predicted Probability of Voluntary Action\") + \n",
    "    xlab(\"Year of Birth (Scaled)\") + \n",
    "    ggtitle(\"Neural Net: \\n Predicted Probabilites of Voluntary Action for a range of Year of Births\") + \n",
    "    scale_x_continuous(breaks = range) + \n",
    "    theme_bw() \n",
    "print(myplot)\n",
    "dev.off()\n",
    "print(myplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "rf2_pred <- h2o.predict(rf2, h2o.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf <- data.frame(cbind(range, as.vector(rf2_pred$p1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAA/wAzMzNNTU1o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\niaIWKESiqAXq/0x3JLq+lzrGAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "png(\"rf-age-volact.png\")\n",
    "myplot <- ggplot(df_rf,aes(x = df_rf[,1], y = df_rf[,2], ymin = 0, ymax = 0)) + \n",
    "    geom_pointrange(col = \"green\") + \n",
    "    ylab(\"Predicted Probability of Voluntary Action\") + \n",
    "    xlab(\"Year of Birth (Scaled)\") + \n",
    "    ggtitle(\"Random Forest: \\n Predicted Probabilites of Voluntary Action for a range of Year of Births\") + \n",
    "    scale_x_continuous(breaks = range) + \n",
    "    theme_bw() \n",
    "print(myplot)\n",
    "dev.off()\n",
    "print(myplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "## rest in server"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
